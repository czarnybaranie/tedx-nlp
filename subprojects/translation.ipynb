{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T11:36:44.519370Z","iopub.execute_input":"2024-12-30T11:36:44.519657Z","iopub.status.idle":"2024-12-30T11:36:44.541386Z","shell.execute_reply.started":"2024-12-30T11:36:44.519629Z","shell.execute_reply":"2024-12-30T11:36:44.540669Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/checkpoint-for-translation/translation_checkpoint-loaded.csv\n/kaggle/input/translation-checkpoint2/translation2_checkpoint-loaded.csv\n/kaggle/input/tedy-with-lang/tedx_videos_extended_with_lang.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\narticle_hi = \"Empresas: um espetáculo à parte\"\narticle_ar = \"Errei, parei! Que erro!\"\n\nmodel = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\ntokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n\n# translate Hindi to French\ntokenizer.src_lang = \"pt_XX\"\nencoded_hi = tokenizer(article_hi, return_tensors=\"pt\")\ngenerated_tokens = model.generate(\n    **encoded_hi,\n    forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]\n)\ntekst1 = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n# => \"Le chef de l 'ONU affirme qu 'il n 'y a pas de solution militaire dans la Syrie.\"\n\n# translate Arabic to English\ntokenizer.src_lang = \"it_IT\"\nencoded_ar = tokenizer(article_ar, return_tensors=\"pt\")\ngenerated_tokens = model.generate(\n    **encoded_ar,\n    forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]\n)\ntekst2 = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n# => \"The Secretary-General of the United Nations says there is no military solution in Syria.\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T12:44:15.012931Z","iopub.execute_input":"2024-12-29T12:44:15.013208Z","iopub.status.idle":"2024-12-29T12:44:27.881134Z","shell.execute_reply.started":"2024-12-29T12:44:15.013189Z","shell.execute_reply":"2024-12-29T12:44:27.880042Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(tekst1)\nprint(tekst2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T12:44:27.882112Z","iopub.execute_input":"2024-12-29T12:44:27.882396Z","iopub.status.idle":"2024-12-29T12:44:27.886757Z","shell.execute_reply.started":"2024-12-29T12:44:27.882373Z","shell.execute_reply":"2024-12-29T12:44:27.885921Z"}},"outputs":[{"name":"stdout","text":"['Companies: a one-off show.']\n[\"You're wrong, stop! You're wrong!\"]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n# Sprawdzenie, czy GPU jest dostępne\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\narticle_hi = \"Empresas: um espetáculo à parte\"\narticle_ar = \"Errei, parei! Que erro!\"\n\n# Załadowanie modelu i tokenizera\nmodel = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\").to(device)\ntokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n\n# Tłumaczenie z Hindi na Francuski\ntokenizer.src_lang = \"pt_XX\"\nencoded_hi = tokenizer(article_hi, return_tensors=\"pt\").to(device)\ngenerated_tokens = model.generate(\n    **encoded_hi,\n    forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]\n)\ntekst1 = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\nprint(tekst1)  # => \"Le chef de l 'ONU affirme qu 'il n 'y a pas de solution militaire dans la Syrie.\"\n\n# Tłumaczenie z Arabskiego na Angielski\ntokenizer.src_lang = \"it_IT\"\nencoded_ar = tokenizer(article_ar, return_tensors=\"pt\").to(device)\ngenerated_tokens = model.generate(\n    **encoded_ar,\n    forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]\n)\ntekst2 = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\nprint(tekst2)  # => \"The Secretary-General of the United Nations says there is no military solution in Syria.\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T12:45:38.473776Z","iopub.execute_input":"2024-12-29T12:45:38.474097Z","iopub.status.idle":"2024-12-29T12:45:47.645531Z","shell.execute_reply.started":"2024-12-29T12:45:38.474072Z","shell.execute_reply":"2024-12-29T12:45:47.644823Z"}},"outputs":[{"name":"stdout","text":"['Companies: a one-off show.']\n[\"You're wrong, stop! You're wrong!\"]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(tekst1)\nprint(tekst2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T12:45:47.646811Z","iopub.execute_input":"2024-12-29T12:45:47.647165Z","iopub.status.idle":"2024-12-29T12:45:47.651691Z","shell.execute_reply.started":"2024-12-29T12:45:47.647122Z","shell.execute_reply":"2024-12-29T12:45:47.650884Z"}},"outputs":[{"name":"stdout","text":"['Companies: a one-off show.']\n[\"You're wrong, stop! You're wrong!\"]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"language_dict = {\n    \"ar\": \"ar_AR\",\n    \"cs\": \"cs_CZ\",\n    \"de\": \"de_DE\",\n    \"en\": \"en_XX\",\n    \"es\": \"es_XX\",\n    \"et\": \"et_EE\",\n    \"fi\": \"fi_FI\",\n    \"fr\": \"fr_XX\",\n    \"gu\": \"gu_IN\",\n    \"hi\": \"hi_IN\",\n    \"it\": \"it_IT\",\n    \"ja\": \"ja_XX\",\n    \"kk\": \"kk_KZ\",\n    \"ko\": \"ko_KR\",\n    \"lt\": \"lt_LT\",\n    \"lv\": \"lv_LV\",\n    \"my\": \"my_MM\",\n    \"ne\": \"ne_NP\",\n    \"nl\": \"nl_XX\",\n    \"ro\": \"ro_RO\",\n    \"ru\": \"ru_RU\",\n    \"si\": \"si_LK\",\n    \"tr\": \"tr_TR\",\n    \"vi\": \"vi_VN\",\n    \"zh\": \"zh_CN\",\n    \"af\": \"af_ZA\",\n    \"az\": \"az_AZ\",\n    \"bn\": \"bn_IN\",\n    \"fa\": \"fa_IR\",\n    \"he\": \"he_IL\",\n    \"hr\": \"hr_HR\",\n    \"id\": \"id_ID\",\n    \"ka\": \"ka_GE\",\n    \"km\": \"km_KH\",\n    \"mk\": \"mk_MK\",\n    \"ml\": \"ml_IN\",\n    \"mn\": \"mn_MN\",\n    \"mr\": \"mr_IN\",\n    \"pl\": \"pl_PL\",\n    \"ps\": \"ps_AF\",\n    \"pt\": \"pt_XX\",\n    \"sv\": \"sv_SE\",\n    \"sw\": \"sw_KE\",\n    \"ta\": \"ta_IN\",\n    \"te\": \"te_IN\",\n    \"th\": \"th_TH\",\n    \"tl\": \"tl_XX\",\n    \"uk\": \"uk_UA\",\n    \"ur\": \"ur_PK\",\n    \"xh\": \"xh_ZA\",\n    \"gl\": \"gl_ES\",\n    \"sl\": \"sl_SI\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T11:36:44.542071Z","iopub.execute_input":"2024-12-30T11:36:44.542368Z","iopub.status.idle":"2024-12-30T11:36:47.959127Z","shell.execute_reply.started":"2024-12-30T11:36:44.542335Z","shell.execute_reply":"2024-12-30T11:36:47.958115Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# translation","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\ndef translate_text(df):\n    translated_texts = []  # Lista na przetłumaczone teksty\n    \n    # Dodajemy pasek postępu do pętli\n    for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Tłumaczenie tekstów\", unit=\"wiersz\"):\n        # Sprawdzamy, czy język jest w słowniku\n        language_code = row['language']  # Zakłada, że język w 'language' to np. \"pt_XX\"\n        \n        if language_code in language_dict:\n            # Ustawiamy język źródłowy tokenizera\n            tokenizer.src_lang = language_dict[language_code]\n            \n            # Przetwarzamy tekst\n            encoded_text = tokenizer(row['title'], return_tensors=\"pt\").to(device)\n            generated_tokens = model.generate(\n                **encoded_text,\n                forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]  # Tłumaczymy na angielski\n            )\n            translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n            translated_texts.append(translated_text)\n        else:\n            # Jeśli język nie jest w słowniku, dodajemy None\n            translated_texts.append(None)\n    \n    # Dodajemy kolumnę z przetłumaczonymi tekstami\n    df['translated_text'] = translated_texts\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T12:51:58.218221Z","iopub.execute_input":"2024-12-29T12:51:58.218547Z","iopub.status.idle":"2024-12-29T12:51:58.224358Z","shell.execute_reply.started":"2024-12-29T12:51:58.218521Z","shell.execute_reply":"2024-12-29T12:51:58.223383Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import pandas as pd\ndf_en = pd.read_csv(\"/kaggle/input/tedy-with-lang/tedx_videos_extended_with_lang.csv\")\ndf_en","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T19:45:15.225884Z","iopub.execute_input":"2024-12-29T19:45:15.226159Z","iopub.status.idle":"2024-12-29T19:45:16.727284Z","shell.execute_reply.started":"2024-12-29T19:45:15.226139Z","shell.execute_reply":"2024-12-29T19:45:16.726405Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                               full_title    views  \\\n0       What Shakespeare teaches us about modern consp...  15518.0   \n1       How poetry saved me from a cult | Diannely Ant...  14758.0   \n2       Why language shapes identity (more than race) ...  25684.0   \n3       On designing a presidential library | Craig Dy...  14181.0   \n4       Why chasing happiness is nuts: What to do inst...  10858.0   \n...                                                   ...      ...   \n226747      TEDxWarwick - Professor Vinesh Raja - 2/28/09   2474.0   \n226748     TEDxWarwick - Professor Steve Fuller - 2/28/09   8460.0   \n226749              TEDxWarwick - Francois Grey - 2/28/09   3480.0   \n226750    TEDxWarwick - Professor Andrew Oswald - 2/28/09   6390.0   \n226751  TEDxWarwick - Professor Philip Zimbardo - 2/28/09  30391.0   \n\n                                    date_str                 date  year  \\\n0       23 godziny temu 13 minut i 11 sekund  2024-12-24 01:00:00  2024   \n1                      1 dzień temu 21 minut  2024-12-24 00:00:00  2024   \n2           2 dni temu 13 minut i 52 sekundy  2024-12-23 00:00:00  2024   \n3                        3 dni temu 20 minut  2024-12-22 00:00:00  2024   \n4                        4 dni temu 16 minut  2024-12-21 00:00:00  2024   \n...                                      ...                  ...   ...   \n226747               15 years ago 29 minutes           2009-12-25  2009   \n226748               15 years ago 24 minutes           2009-12-25  2009   \n226749               15 years ago 27 minutes           2009-12-25  2009   \n226750               15 years ago 24 minutes           2009-12-25  2009   \n226751               15 years ago 27 minutes           2009-12-25  2009   \n\n                                                    title           speaker  \\\n0       What Shakespeare teaches us about modern consp...    Dr. Paul Budra   \n1                         How poetry saved me from a cult  Diannely Antigua   \n2           Why language shapes identity (more than race)      Malaka Grant   \n3                     On designing a presidential library      Craig Dykers   \n4       Why chasing happiness is nuts: What to do instead    Lenorë Lambert   \n...                                                   ...               ...   \n226747      TEDxWarwick - Professor Vinesh Raja - 2/28/09               NaN   \n226748     TEDxWarwick - Professor Steve Fuller - 2/28/09               NaN   \n226749              TEDxWarwick - Francois Grey - 2/28/09               NaN   \n226750    TEDxWarwick - Professor Andrew Oswald - 2/28/09               NaN   \n226751  TEDxWarwick - Professor Philip Zimbardo - 2/28/09               NaN   \n\n                  event language  \n0       TEDxSurreySalon       en  \n1        TEDxPortsmouth       en  \n2            TEDxGeorge       en  \n3             TEDxFargo       es  \n4          TEDxBillings       en  \n...                 ...      ...  \n226747              NaN       en  \n226748              NaN       en  \n226749              NaN       en  \n226750              NaN       en  \n226751              NaN       en  \n\n[226752 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_title</th>\n      <th>views</th>\n      <th>date_str</th>\n      <th>date</th>\n      <th>year</th>\n      <th>title</th>\n      <th>speaker</th>\n      <th>event</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What Shakespeare teaches us about modern consp...</td>\n      <td>15518.0</td>\n      <td>23 godziny temu 13 minut i 11 sekund</td>\n      <td>2024-12-24 01:00:00</td>\n      <td>2024</td>\n      <td>What Shakespeare teaches us about modern consp...</td>\n      <td>Dr. Paul Budra</td>\n      <td>TEDxSurreySalon</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How poetry saved me from a cult | Diannely Ant...</td>\n      <td>14758.0</td>\n      <td>1 dzień temu 21 minut</td>\n      <td>2024-12-24 00:00:00</td>\n      <td>2024</td>\n      <td>How poetry saved me from a cult</td>\n      <td>Diannely Antigua</td>\n      <td>TEDxPortsmouth</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why language shapes identity (more than race) ...</td>\n      <td>25684.0</td>\n      <td>2 dni temu 13 minut i 52 sekundy</td>\n      <td>2024-12-23 00:00:00</td>\n      <td>2024</td>\n      <td>Why language shapes identity (more than race)</td>\n      <td>Malaka Grant</td>\n      <td>TEDxGeorge</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>On designing a presidential library | Craig Dy...</td>\n      <td>14181.0</td>\n      <td>3 dni temu 20 minut</td>\n      <td>2024-12-22 00:00:00</td>\n      <td>2024</td>\n      <td>On designing a presidential library</td>\n      <td>Craig Dykers</td>\n      <td>TEDxFargo</td>\n      <td>es</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Why chasing happiness is nuts: What to do inst...</td>\n      <td>10858.0</td>\n      <td>4 dni temu 16 minut</td>\n      <td>2024-12-21 00:00:00</td>\n      <td>2024</td>\n      <td>Why chasing happiness is nuts: What to do instead</td>\n      <td>Lenorë Lambert</td>\n      <td>TEDxBillings</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>226747</th>\n      <td>TEDxWarwick - Professor Vinesh Raja - 2/28/09</td>\n      <td>2474.0</td>\n      <td>15 years ago 29 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Vinesh Raja - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226748</th>\n      <td>TEDxWarwick - Professor Steve Fuller - 2/28/09</td>\n      <td>8460.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Steve Fuller - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226749</th>\n      <td>TEDxWarwick - Francois Grey - 2/28/09</td>\n      <td>3480.0</td>\n      <td>15 years ago 27 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Francois Grey - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226750</th>\n      <td>TEDxWarwick - Professor Andrew Oswald - 2/28/09</td>\n      <td>6390.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Andrew Oswald - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226751</th>\n      <td>TEDxWarwick - Professor Philip Zimbardo - 2/28/09</td>\n      <td>30391.0</td>\n      <td>15 years ago 27 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Philip Zimbardo - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n<p>226752 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df = df_en[df_en['language'] != 'en']\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T19:45:16.926823Z","iopub.execute_input":"2024-12-29T19:45:16.927137Z","iopub.status.idle":"2024-12-29T19:45:16.970315Z","shell.execute_reply.started":"2024-12-29T19:45:16.927110Z","shell.execute_reply":"2024-12-29T19:45:16.969558Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                               full_title     views  \\\n3       On designing a presidential library | Craig Dy...   14181.0   \n22      Empresas: um espetáculo à parte | Flávia Macie...     118.0   \n23      O poder das palavras | Nicolas Oliveira | TEDx...     139.0   \n24      Errei, parei! Que erro! | Fábio Paixão | TEDxM...      58.0   \n25      KENDİNİZE HOŞGELDİNİZ | Hakan Bilgin | TEDxAta...     504.0   \n...                                                   ...       ...   \n226741                     TEDxKL - Yasmin Ahmad - 6/3/09  179759.0   \n226743                   TEDxWarwick | Solitaire Townsend    4353.0   \n226744     TEDxWarwick - Professor Steve Furber - 2/28/09    4291.0   \n226745                       TEDxWarwick | Dr Ian Pearson   12286.0   \n226746                TEDxWarwick - Jay Lakhani - 2/28/09   33476.0   \n\n                                   date_str                 date  year  \\\n3                       3 dni temu 20 minut  2024-12-22 00:00:00  2024   \n22          5 dni temu 6 minut i 52 sekundy  2024-12-20 00:00:00  2024   \n23           5 dni temu 6 minut i 17 sekund  2024-12-20 00:00:00  2024   \n24           5 dni temu 8 minut i 14 sekund  2024-12-20 00:00:00  2024   \n25                      5 dni temu 16 minut  2024-12-20 00:00:00  2024   \n...                                     ...                  ...   ...   \n226741  15 years ago 14 minutes, 35 seconds           2009-12-25  2009   \n226743              15 years ago 32 minutes           2009-12-25  2009   \n226744              15 years ago 24 minutes           2009-12-25  2009   \n226745              15 years ago 25 minutes           2009-12-25  2009   \n226746              15 years ago 24 minutes           2009-12-25  2009   \n\n                                                 title             speaker  \\\n3                  On designing a presidential library        Craig Dykers   \n22                     Empresas: um espetáculo à parte       Flávia Maciel   \n23                                O poder das palavras    Nicolas Oliveira   \n24                             Errei, parei! Que erro!        Fábio Paixão   \n25                               KENDİNİZE HOŞGELDİNİZ        Hakan Bilgin   \n...                                                ...                 ...   \n226741                  TEDxKL - Yasmin Ahmad - 6/3/09                 NaN   \n226743                                     TEDxWarwick  Solitaire Townsend   \n226744  TEDxWarwick - Professor Steve Furber - 2/28/09                 NaN   \n226745                                     TEDxWarwick      Dr Ian Pearson   \n226746             TEDxWarwick - Jay Lakhani - 2/28/09                 NaN   \n\n                    event language  \n3               TEDxFargo       es  \n22      TEDxMaringáStudio       pt  \n23      TEDxMaringáStudio       pt  \n24      TEDxMaringáStudio       it  \n25            TEDxAtapark       vi  \n...                   ...      ...  \n226741                NaN       tr  \n226743                NaN       pl  \n226744                NaN       de  \n226745                NaN       pl  \n226746                NaN       so  \n\n[70213 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_title</th>\n      <th>views</th>\n      <th>date_str</th>\n      <th>date</th>\n      <th>year</th>\n      <th>title</th>\n      <th>speaker</th>\n      <th>event</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>On designing a presidential library | Craig Dy...</td>\n      <td>14181.0</td>\n      <td>3 dni temu 20 minut</td>\n      <td>2024-12-22 00:00:00</td>\n      <td>2024</td>\n      <td>On designing a presidential library</td>\n      <td>Craig Dykers</td>\n      <td>TEDxFargo</td>\n      <td>es</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Empresas: um espetáculo à parte | Flávia Macie...</td>\n      <td>118.0</td>\n      <td>5 dni temu 6 minut i 52 sekundy</td>\n      <td>2024-12-20 00:00:00</td>\n      <td>2024</td>\n      <td>Empresas: um espetáculo à parte</td>\n      <td>Flávia Maciel</td>\n      <td>TEDxMaringáStudio</td>\n      <td>pt</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>O poder das palavras | Nicolas Oliveira | TEDx...</td>\n      <td>139.0</td>\n      <td>5 dni temu 6 minut i 17 sekund</td>\n      <td>2024-12-20 00:00:00</td>\n      <td>2024</td>\n      <td>O poder das palavras</td>\n      <td>Nicolas Oliveira</td>\n      <td>TEDxMaringáStudio</td>\n      <td>pt</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Errei, parei! Que erro! | Fábio Paixão | TEDxM...</td>\n      <td>58.0</td>\n      <td>5 dni temu 8 minut i 14 sekund</td>\n      <td>2024-12-20 00:00:00</td>\n      <td>2024</td>\n      <td>Errei, parei! Que erro!</td>\n      <td>Fábio Paixão</td>\n      <td>TEDxMaringáStudio</td>\n      <td>it</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>KENDİNİZE HOŞGELDİNİZ | Hakan Bilgin | TEDxAta...</td>\n      <td>504.0</td>\n      <td>5 dni temu 16 minut</td>\n      <td>2024-12-20 00:00:00</td>\n      <td>2024</td>\n      <td>KENDİNİZE HOŞGELDİNİZ</td>\n      <td>Hakan Bilgin</td>\n      <td>TEDxAtapark</td>\n      <td>vi</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>226741</th>\n      <td>TEDxKL - Yasmin Ahmad - 6/3/09</td>\n      <td>179759.0</td>\n      <td>15 years ago 14 minutes, 35 seconds</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxKL - Yasmin Ahmad - 6/3/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>226743</th>\n      <td>TEDxWarwick | Solitaire Townsend</td>\n      <td>4353.0</td>\n      <td>15 years ago 32 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick</td>\n      <td>Solitaire Townsend</td>\n      <td>NaN</td>\n      <td>pl</td>\n    </tr>\n    <tr>\n      <th>226744</th>\n      <td>TEDxWarwick - Professor Steve Furber - 2/28/09</td>\n      <td>4291.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Steve Furber - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>de</td>\n    </tr>\n    <tr>\n      <th>226745</th>\n      <td>TEDxWarwick | Dr Ian Pearson</td>\n      <td>12286.0</td>\n      <td>15 years ago 25 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick</td>\n      <td>Dr Ian Pearson</td>\n      <td>NaN</td>\n      <td>pl</td>\n    </tr>\n    <tr>\n      <th>226746</th>\n      <td>TEDxWarwick - Jay Lakhani - 2/28/09</td>\n      <td>33476.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Jay Lakhani - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>so</td>\n    </tr>\n  </tbody>\n</table>\n<p>70213 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Przetłumaczenie tekstów\ndf_translated = translate_text(df)\n\n# Wyświetlanie przetłumaczonego DataFrame\nprint(df_translated)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T12:52:01.969103Z","iopub.execute_input":"2024-12-29T12:52:01.969418Z","iopub.status.idle":"2024-12-29T12:53:15.201553Z","shell.execute_reply.started":"2024-12-29T12:52:01.969390Z","shell.execute_reply":"2024-12-29T12:53:15.200369Z"}},"outputs":[{"name":"stderr","text":"Tłumaczenie tekstów:   0%|          | 136/70213 [01:13<10:28:39,  1.86wiersz/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-b2ea90fe6a99>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Przetłumaczenie tekstów\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_translated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Wyświetlanie przetłumaczonego DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_translated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-09568817151d>\u001b[0m in \u001b[0;36mtranslate_text\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# Przetwarzamy tekst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mencoded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             generated_tokens = model.generate(\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mencoded_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mforced_bos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang_code_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"en_XX\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Tłumaczymy na angielski\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2064\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m             \u001b[0;31m# stateless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m             beam_outputs = beam_scorer.process(\n\u001b[0m\u001b[1;32m   3301\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m                 \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/beam_search.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id, beam_indices, group_index, decoder_prompt_len)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mbatch_group_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_beam_groups\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgroup_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_group_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_beams\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_beam_hyps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_group_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Batch can only be done if at least {self.num_beams} beams have been generated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":25},{"cell_type":"code","source":"#optimized func\nimport pandas as pd\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\nimport torch\nfrom tqdm import tqdm\n\n# Sprawdzenie, czy GPU jest dostępne\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Załadowanie modelu i tokenizera raz\nmodel = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\").to(device)\ntokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n\n# Słownik z językami (przykładowy fragment)\nlanguage_dict = {\n    \"ar\": \"ar_AR\",\n    \"cs\": \"cs_CZ\",\n    \"de\": \"de_DE\",\n    \"en\": \"en_XX\",\n    \"es\": \"es_XX\",\n    \"fr\": \"fr_XX\",\n    \"hi\": \"hi_IN\",\n    \"it\": \"it_IT\",\n    \"pl\": \"pl_PL\",\n    \"pt\": \"pt_XX\",\n    \"ru\": \"ru_RU\",\n    \"zh\": \"zh_CN\"\n}\n\ndef translate_text(df):\n    translated_texts = []  # Lista na przetłumaczone teksty\n    \n    # Będziemy tłumaczyć partie tekstów, zamiast pojedynczych wierszy\n    batch_size = 16  # Możesz dostosować rozmiar partii\n    for i in tqdm(range(0, df.shape[0], batch_size), desc=\"Tłumaczenie tekstów\", unit=\"partia\"):\n        batch = df.iloc[i:i+batch_size]  # Pobieramy partię wierszy\n        \n        # Lista dla przetłumaczonych tekstów w partii\n        batch_translated_texts = []\n        \n        for _, row in batch.iterrows():\n            # Sprawdzamy, czy język jest w słowniku\n            language_code = row['language']  # Zakłada, że język w 'language' to np. \"pt_XX\"\n            \n            if language_code in language_dict:\n                # Ustawiamy język źródłowy tokenizera\n                tokenizer.src_lang = language_dict[language_code]\n                \n                # Przetwarzamy tekst\n                encoded_text = tokenizer(row['title'], return_tensors=\"pt\").to(device)\n                generated_tokens = model.generate(\n                    **encoded_text,\n                    forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]  # Tłumaczymy na angielski\n                )\n                translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n                batch_translated_texts.append(translated_text)\n            else:\n                # Jeśli język nie jest w słowniku, dodajemy None\n                batch_translated_texts.append(None)\n        \n        # Dodajemy przetłumaczone teksty do listy\n        translated_texts.extend(batch_translated_texts)\n    \n    # Dodajemy kolumnę z przetłumaczonymi tekstami\n    df['translated_text'] = translated_texts\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T12:53:56.961652Z","iopub.execute_input":"2024-12-29T12:53:56.961941Z","iopub.status.idle":"2024-12-29T12:54:04.941294Z","shell.execute_reply.started":"2024-12-29T12:53:56.961920Z","shell.execute_reply":"2024-12-29T12:54:04.940590Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Przetłumaczenie tekstów\ndf_translated = translate_text(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T12:54:15.911333Z","iopub.execute_input":"2024-12-29T12:54:15.911676Z","iopub.status.idle":"2024-12-29T12:55:46.748161Z","shell.execute_reply.started":"2024-12-29T12:54:15.911650Z","shell.execute_reply":"2024-12-29T12:55:46.747026Z"}},"outputs":[{"name":"stderr","text":"Tłumaczenie tekstów:   0%|          | 12/4389 [01:30<9:12:03,  7.57s/partia] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-b73aadb35c24>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Przetłumaczenie tekstów\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_translated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-26-068cb4612ec5>\u001b[0m in \u001b[0;36mtranslate_text\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m# Przetwarzamy tekst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mencoded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 generated_tokens = model.generate(\n\u001b[0m\u001b[1;32m     52\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mencoded_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0mforced_bos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang_code_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"en_XX\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Tłumaczymy na angielski\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2064\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m             \u001b[0;31m# stateless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m             beam_outputs = beam_scorer.process(\n\u001b[0m\u001b[1;32m   3301\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m                 \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/beam_search.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id, beam_indices, group_index, decoder_prompt_len)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;31m# Check if we are done so that we can save a pad step if all(done)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             self._done[batch_group_idx] = self._done[batch_group_idx] or self._beam_hyps[batch_group_idx].is_done(\n\u001b[0;32m--> 309\u001b[0;31m                 \u001b[0mnext_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_prompt_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             )\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:03:44.639183Z","iopub.execute_input":"2024-12-29T13:03:44.639473Z","iopub.status.idle":"2024-12-29T13:03:52.770521Z","shell.execute_reply.started":"2024-12-29T13:03:44.639452Z","shell.execute_reply":"2024-12-29T13:03:52.769825Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"language_dict = {\n    \"ar\": \"ar_AR\",\n    \"cs\": \"cs_CZ\",\n    \"de\": \"de_DE\",\n    \"en\": \"en_XX\",\n    \"es\": \"es_XX\",\n    \"et\": \"et_EE\",\n    \"fi\": \"fi_FI\",\n    \"fr\": \"fr_XX\",\n    \"gu\": \"gu_IN\",\n    \"hi\": \"hi_IN\",\n    \"it\": \"it_IT\",\n    \"ja\": \"ja_XX\",\n    \"kk\": \"kk_KZ\",\n    \"ko\": \"ko_KR\",\n    \"lt\": \"lt_LT\",\n    \"lv\": \"lv_LV\",\n    \"my\": \"my_MM\",\n    \"ne\": \"ne_NP\",\n    \"nl\": \"nl_XX\",\n    \"ro\": \"ro_RO\",\n    \"ru\": \"ru_RU\",\n    \"si\": \"si_LK\",\n    \"tr\": \"tr_TR\",\n    \"vi\": \"vi_VN\",\n    \"zh\": \"zh_CN\",\n    \"af\": \"af_ZA\",\n    \"az\": \"az_AZ\",\n    \"bn\": \"bn_IN\",\n    \"fa\": \"fa_IR\",\n    \"he\": \"he_IL\",\n    \"hr\": \"hr_HR\",\n    \"id\": \"id_ID\",\n    \"ka\": \"ka_GE\",\n    \"km\": \"km_KH\",\n    \"mk\": \"mk_MK\",\n    \"ml\": \"ml_IN\",\n    \"mn\": \"mn_MN\",\n    \"mr\": \"mr_IN\",\n    \"pl\": \"pl_PL\",\n    \"ps\": \"ps_AF\",\n    \"pt\": \"pt_XX\",\n    \"sv\": \"sv_SE\",\n    \"sw\": \"sw_KE\",\n    \"ta\": \"ta_IN\",\n    \"te\": \"te_IN\",\n    \"th\": \"th_TH\",\n    \"tl\": \"tl_XX\",\n    \"uk\": \"uk_UA\",\n    \"ur\": \"ur_PK\",\n    \"xh\": \"xh_ZA\",\n    \"gl\": \"gl_ES\",\n    \"sl\": \"sl_SI\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T10:57:12.344596Z","iopub.execute_input":"2024-12-30T10:57:12.344990Z","iopub.status.idle":"2024-12-30T10:57:12.350610Z","shell.execute_reply.started":"2024-12-30T10:57:12.344964Z","shell.execute_reply":"2024-12-30T10:57:12.349823Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\ndf_en = pd.read_csv(\"/kaggle/input/tedy-with-lang/tedx_videos_extended_with_lang.csv\")\ndf_en","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T19:42:13.862491Z","iopub.execute_input":"2024-12-29T19:42:13.862941Z","iopub.status.idle":"2024-12-29T19:42:15.280728Z","shell.execute_reply.started":"2024-12-29T19:42:13.862914Z","shell.execute_reply":"2024-12-29T19:42:15.279658Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                               full_title    views  \\\n0       What Shakespeare teaches us about modern consp...  15518.0   \n1       How poetry saved me from a cult | Diannely Ant...  14758.0   \n2       Why language shapes identity (more than race) ...  25684.0   \n3       On designing a presidential library | Craig Dy...  14181.0   \n4       Why chasing happiness is nuts: What to do inst...  10858.0   \n...                                                   ...      ...   \n226747      TEDxWarwick - Professor Vinesh Raja - 2/28/09   2474.0   \n226748     TEDxWarwick - Professor Steve Fuller - 2/28/09   8460.0   \n226749              TEDxWarwick - Francois Grey - 2/28/09   3480.0   \n226750    TEDxWarwick - Professor Andrew Oswald - 2/28/09   6390.0   \n226751  TEDxWarwick - Professor Philip Zimbardo - 2/28/09  30391.0   \n\n                                    date_str                 date  year  \\\n0       23 godziny temu 13 minut i 11 sekund  2024-12-24 01:00:00  2024   \n1                      1 dzień temu 21 minut  2024-12-24 00:00:00  2024   \n2           2 dni temu 13 minut i 52 sekundy  2024-12-23 00:00:00  2024   \n3                        3 dni temu 20 minut  2024-12-22 00:00:00  2024   \n4                        4 dni temu 16 minut  2024-12-21 00:00:00  2024   \n...                                      ...                  ...   ...   \n226747               15 years ago 29 minutes           2009-12-25  2009   \n226748               15 years ago 24 minutes           2009-12-25  2009   \n226749               15 years ago 27 minutes           2009-12-25  2009   \n226750               15 years ago 24 minutes           2009-12-25  2009   \n226751               15 years ago 27 minutes           2009-12-25  2009   \n\n                                                    title           speaker  \\\n0       What Shakespeare teaches us about modern consp...    Dr. Paul Budra   \n1                         How poetry saved me from a cult  Diannely Antigua   \n2           Why language shapes identity (more than race)      Malaka Grant   \n3                     On designing a presidential library      Craig Dykers   \n4       Why chasing happiness is nuts: What to do instead    Lenorë Lambert   \n...                                                   ...               ...   \n226747      TEDxWarwick - Professor Vinesh Raja - 2/28/09               NaN   \n226748     TEDxWarwick - Professor Steve Fuller - 2/28/09               NaN   \n226749              TEDxWarwick - Francois Grey - 2/28/09               NaN   \n226750    TEDxWarwick - Professor Andrew Oswald - 2/28/09               NaN   \n226751  TEDxWarwick - Professor Philip Zimbardo - 2/28/09               NaN   \n\n                  event language  \n0       TEDxSurreySalon       en  \n1        TEDxPortsmouth       en  \n2            TEDxGeorge       en  \n3             TEDxFargo       es  \n4          TEDxBillings       en  \n...                 ...      ...  \n226747              NaN       en  \n226748              NaN       en  \n226749              NaN       en  \n226750              NaN       en  \n226751              NaN       en  \n\n[226752 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_title</th>\n      <th>views</th>\n      <th>date_str</th>\n      <th>date</th>\n      <th>year</th>\n      <th>title</th>\n      <th>speaker</th>\n      <th>event</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What Shakespeare teaches us about modern consp...</td>\n      <td>15518.0</td>\n      <td>23 godziny temu 13 minut i 11 sekund</td>\n      <td>2024-12-24 01:00:00</td>\n      <td>2024</td>\n      <td>What Shakespeare teaches us about modern consp...</td>\n      <td>Dr. Paul Budra</td>\n      <td>TEDxSurreySalon</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How poetry saved me from a cult | Diannely Ant...</td>\n      <td>14758.0</td>\n      <td>1 dzień temu 21 minut</td>\n      <td>2024-12-24 00:00:00</td>\n      <td>2024</td>\n      <td>How poetry saved me from a cult</td>\n      <td>Diannely Antigua</td>\n      <td>TEDxPortsmouth</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why language shapes identity (more than race) ...</td>\n      <td>25684.0</td>\n      <td>2 dni temu 13 minut i 52 sekundy</td>\n      <td>2024-12-23 00:00:00</td>\n      <td>2024</td>\n      <td>Why language shapes identity (more than race)</td>\n      <td>Malaka Grant</td>\n      <td>TEDxGeorge</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>On designing a presidential library | Craig Dy...</td>\n      <td>14181.0</td>\n      <td>3 dni temu 20 minut</td>\n      <td>2024-12-22 00:00:00</td>\n      <td>2024</td>\n      <td>On designing a presidential library</td>\n      <td>Craig Dykers</td>\n      <td>TEDxFargo</td>\n      <td>es</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Why chasing happiness is nuts: What to do inst...</td>\n      <td>10858.0</td>\n      <td>4 dni temu 16 minut</td>\n      <td>2024-12-21 00:00:00</td>\n      <td>2024</td>\n      <td>Why chasing happiness is nuts: What to do instead</td>\n      <td>Lenorë Lambert</td>\n      <td>TEDxBillings</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>226747</th>\n      <td>TEDxWarwick - Professor Vinesh Raja - 2/28/09</td>\n      <td>2474.0</td>\n      <td>15 years ago 29 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Vinesh Raja - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226748</th>\n      <td>TEDxWarwick - Professor Steve Fuller - 2/28/09</td>\n      <td>8460.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Steve Fuller - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226749</th>\n      <td>TEDxWarwick - Francois Grey - 2/28/09</td>\n      <td>3480.0</td>\n      <td>15 years ago 27 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Francois Grey - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226750</th>\n      <td>TEDxWarwick - Professor Andrew Oswald - 2/28/09</td>\n      <td>6390.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Andrew Oswald - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226751</th>\n      <td>TEDxWarwick - Professor Philip Zimbardo - 2/28/09</td>\n      <td>30391.0</td>\n      <td>15 years ago 27 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Philip Zimbardo - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n<p>226752 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df = df_en[df_en['language'] != 'en']\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T19:42:18.430704Z","iopub.execute_input":"2024-12-29T19:42:18.431024Z","iopub.status.idle":"2024-12-29T19:42:18.468831Z","shell.execute_reply.started":"2024-12-29T19:42:18.430998Z","shell.execute_reply":"2024-12-29T19:42:18.468100Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                               full_title     views  \\\n3       On designing a presidential library | Craig Dy...   14181.0   \n22      Empresas: um espetáculo à parte | Flávia Macie...     118.0   \n23      O poder das palavras | Nicolas Oliveira | TEDx...     139.0   \n24      Errei, parei! Que erro! | Fábio Paixão | TEDxM...      58.0   \n25      KENDİNİZE HOŞGELDİNİZ | Hakan Bilgin | TEDxAta...     504.0   \n...                                                   ...       ...   \n226741                     TEDxKL - Yasmin Ahmad - 6/3/09  179759.0   \n226743                   TEDxWarwick | Solitaire Townsend    4353.0   \n226744     TEDxWarwick - Professor Steve Furber - 2/28/09    4291.0   \n226745                       TEDxWarwick | Dr Ian Pearson   12286.0   \n226746                TEDxWarwick - Jay Lakhani - 2/28/09   33476.0   \n\n                                   date_str                 date  year  \\\n3                       3 dni temu 20 minut  2024-12-22 00:00:00  2024   \n22          5 dni temu 6 minut i 52 sekundy  2024-12-20 00:00:00  2024   \n23           5 dni temu 6 minut i 17 sekund  2024-12-20 00:00:00  2024   \n24           5 dni temu 8 minut i 14 sekund  2024-12-20 00:00:00  2024   \n25                      5 dni temu 16 minut  2024-12-20 00:00:00  2024   \n...                                     ...                  ...   ...   \n226741  15 years ago 14 minutes, 35 seconds           2009-12-25  2009   \n226743              15 years ago 32 minutes           2009-12-25  2009   \n226744              15 years ago 24 minutes           2009-12-25  2009   \n226745              15 years ago 25 minutes           2009-12-25  2009   \n226746              15 years ago 24 minutes           2009-12-25  2009   \n\n                                                 title             speaker  \\\n3                  On designing a presidential library        Craig Dykers   \n22                     Empresas: um espetáculo à parte       Flávia Maciel   \n23                                O poder das palavras    Nicolas Oliveira   \n24                             Errei, parei! Que erro!        Fábio Paixão   \n25                               KENDİNİZE HOŞGELDİNİZ        Hakan Bilgin   \n...                                                ...                 ...   \n226741                  TEDxKL - Yasmin Ahmad - 6/3/09                 NaN   \n226743                                     TEDxWarwick  Solitaire Townsend   \n226744  TEDxWarwick - Professor Steve Furber - 2/28/09                 NaN   \n226745                                     TEDxWarwick      Dr Ian Pearson   \n226746             TEDxWarwick - Jay Lakhani - 2/28/09                 NaN   \n\n                    event language  \n3               TEDxFargo       es  \n22      TEDxMaringáStudio       pt  \n23      TEDxMaringáStudio       pt  \n24      TEDxMaringáStudio       it  \n25            TEDxAtapark       vi  \n...                   ...      ...  \n226741                NaN       tr  \n226743                NaN       pl  \n226744                NaN       de  \n226745                NaN       pl  \n226746                NaN       so  \n\n[70213 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_title</th>\n      <th>views</th>\n      <th>date_str</th>\n      <th>date</th>\n      <th>year</th>\n      <th>title</th>\n      <th>speaker</th>\n      <th>event</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>On designing a presidential library | Craig Dy...</td>\n      <td>14181.0</td>\n      <td>3 dni temu 20 minut</td>\n      <td>2024-12-22 00:00:00</td>\n      <td>2024</td>\n      <td>On designing a presidential library</td>\n      <td>Craig Dykers</td>\n      <td>TEDxFargo</td>\n      <td>es</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Empresas: um espetáculo à parte | Flávia Macie...</td>\n      <td>118.0</td>\n      <td>5 dni temu 6 minut i 52 sekundy</td>\n      <td>2024-12-20 00:00:00</td>\n      <td>2024</td>\n      <td>Empresas: um espetáculo à parte</td>\n      <td>Flávia Maciel</td>\n      <td>TEDxMaringáStudio</td>\n      <td>pt</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>O poder das palavras | Nicolas Oliveira | TEDx...</td>\n      <td>139.0</td>\n      <td>5 dni temu 6 minut i 17 sekund</td>\n      <td>2024-12-20 00:00:00</td>\n      <td>2024</td>\n      <td>O poder das palavras</td>\n      <td>Nicolas Oliveira</td>\n      <td>TEDxMaringáStudio</td>\n      <td>pt</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Errei, parei! Que erro! | Fábio Paixão | TEDxM...</td>\n      <td>58.0</td>\n      <td>5 dni temu 8 minut i 14 sekund</td>\n      <td>2024-12-20 00:00:00</td>\n      <td>2024</td>\n      <td>Errei, parei! Que erro!</td>\n      <td>Fábio Paixão</td>\n      <td>TEDxMaringáStudio</td>\n      <td>it</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>KENDİNİZE HOŞGELDİNİZ | Hakan Bilgin | TEDxAta...</td>\n      <td>504.0</td>\n      <td>5 dni temu 16 minut</td>\n      <td>2024-12-20 00:00:00</td>\n      <td>2024</td>\n      <td>KENDİNİZE HOŞGELDİNİZ</td>\n      <td>Hakan Bilgin</td>\n      <td>TEDxAtapark</td>\n      <td>vi</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>226741</th>\n      <td>TEDxKL - Yasmin Ahmad - 6/3/09</td>\n      <td>179759.0</td>\n      <td>15 years ago 14 minutes, 35 seconds</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxKL - Yasmin Ahmad - 6/3/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>226743</th>\n      <td>TEDxWarwick | Solitaire Townsend</td>\n      <td>4353.0</td>\n      <td>15 years ago 32 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick</td>\n      <td>Solitaire Townsend</td>\n      <td>NaN</td>\n      <td>pl</td>\n    </tr>\n    <tr>\n      <th>226744</th>\n      <td>TEDxWarwick - Professor Steve Furber - 2/28/09</td>\n      <td>4291.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Steve Furber - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>de</td>\n    </tr>\n    <tr>\n      <th>226745</th>\n      <td>TEDxWarwick | Dr Ian Pearson</td>\n      <td>12286.0</td>\n      <td>15 years ago 25 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick</td>\n      <td>Dr Ian Pearson</td>\n      <td>NaN</td>\n      <td>pl</td>\n    </tr>\n    <tr>\n      <th>226746</th>\n      <td>TEDxWarwick - Jay Lakhani - 2/28/09</td>\n      <td>33476.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Jay Lakhani - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>so</td>\n    </tr>\n  </tbody>\n</table>\n<p>70213 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Przetłumaczenie tekstów\ndf_translated = translate_text(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:03:52.771547Z","iopub.execute_input":"2024-12-29T13:03:52.771767Z","iopub.status.idle":"2024-12-29T15:26:27.014519Z","shell.execute_reply.started":"2024-12-29T13:03:52.771749Z","shell.execute_reply":"2024-12-29T15:26:27.013259Z"}},"outputs":[{"name":"stderr","text":"Tłumaczenie tekstów:  84%|████████▍ | 43/51 [2:22:34<26:31, 198.94s/język]    \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b73aadb35c24>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Przetłumaczenie tekstów\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_translated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-a6104e8016d6>\u001b[0m in \u001b[0;36mtranslate_text\u001b[0;34m(df, batch_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# Przetwarzamy teksty w partii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mencoded_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;31m# Generowanie tłumaczeń\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3053\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3055\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3056\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3057\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3140\u001b[0m                 )\n\u001b[1;32m   3141\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3142\u001b[0;31m             return self.batch_encode_plus(\n\u001b[0m\u001b[1;32m   3143\u001b[0m                 \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m                 \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3336\u001b[0m         )\n\u001b[1;32m   3337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3338\u001b[0;31m         return self._batch_encode_plus(\n\u001b[0m\u001b[1;32m   3339\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3340\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_special_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_special_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         encodings = self._tokenizer.encode_batch(\n\u001b[0m\u001b[1;32m    529\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"],"ename":"TypeError","evalue":"TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"df_translated","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T15:29:36.762614Z","iopub.execute_input":"2024-12-29T15:29:36.762923Z","iopub.status.idle":"2024-12-29T15:29:36.776603Z","shell.execute_reply.started":"2024-12-29T15:29:36.762899Z","shell.execute_reply":"2024-12-29T15:29:36.775538Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-d2752631c196>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_translated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df_translated' is not defined"],"ename":"NameError","evalue":"name 'df_translated' is not defined","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"# FINAL AFTER ERROR","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T15:34:58.614898Z","iopub.execute_input":"2024-12-29T15:34:58.615255Z","iopub.status.idle":"2024-12-29T15:34:58.619156Z","shell.execute_reply.started":"2024-12-29T15:34:58.615230Z","shell.execute_reply":"2024-12-29T15:34:58.618074Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# optimized2\nimport pandas as pd\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\nimport torch\nfrom tqdm import tqdm\n\n# Sprawdzenie, czy GPU jest dostępne\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Załadowanie modelu i tokenizera raz\nmodel = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\").to(device)\ntokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T11:36:47.960010Z","iopub.execute_input":"2024-12-30T11:36:47.960346Z","iopub.status.idle":"2024-12-30T11:36:56.564459Z","shell.execute_reply.started":"2024-12-30T11:36:47.960315Z","shell.execute_reply":"2024-12-30T11:36:56.563762Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def translate_text(df, batch_size=8, checkpoint_file=\"translation_checkpoint.csv\"):\n    translated_texts = [None] * len(df)  # Lista na przetłumaczone teksty\n    language_counter = 0  # Licznik do zapisywania checkpointu co 5 języków\n\n    # Zapisz oryginalne indeksy\n    df = df.copy()  # Upewniamy się, że pracujemy na kopii DataFrame\n    df.loc[:, 'original_index'] = df.index\n\n    # Sortowanie danych według języka\n    df_sorted = df.sort_values(by='language').reset_index(drop=True)\n\n    # Przetwarzanie tekstów po kolei\n    current_language = None\n    for idx, row in tqdm(df_sorted.iterrows(), desc=\"Tłumaczenie tekstów\", unit=\"wiersz\"):\n        language_code = row['language']\n        if language_code != current_language:\n            current_language = language_code\n            if language_code in language_dict:\n                print(f\"Przetwarzanie języka: {language_code}\")\n            else:\n                print(f\"Język {language_code} nie jest obsługiwany\")\n\n        if language_code in language_dict:\n            # Ustawiamy język źródłowy tokenizera\n            tokenizer.src_lang = language_dict[language_code]\n\n            # Walidacja danych: odrzucanie nieprawidłowych tekstów\n            text = row['title']\n            if isinstance(text, str) and text.strip() != \"\":\n                # Tokenizacja\n                encoded_texts = tokenizer([text], padding=True, truncation=True, return_tensors=\"pt\").to(device)\n                \n                # Generowanie tłumaczeń\n                generated_tokens = model.generate(\n                    **encoded_texts,\n                    forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]  # Tłumaczymy na angielski\n                )\n                \n                # Dekodowanie przetłumaczonego tekstu\n                translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n                translated_texts[idx] = translated_text\n            else:\n                translated_texts[idx] = None\n\n            language_counter += 1\n            if language_counter % 5000 == 0:\n                # Zapisujemy checkpoint co 5 języków\n                checkpoint_df = df_sorted.copy()\n                checkpoint_df['translated_text'] = translated_texts\n                checkpoint_df.to_csv(checkpoint_file, index=False)\n        else:\n            translated_texts[idx] = None\n\n    # Przypisanie przetłumaczonych tekstów do oryginalnego DataFrame\n    df_sorted.loc[:, 'translated_text'] = translated_texts\n\n    # Przywrócenie oryginalnego porządku\n    result_df = df_sorted.sort_values(by='original_index').drop(columns=['original_index']).reset_index(drop=True)\n\n    # Zapisz końcowy wynik do pliku .csv po przetłumaczeniu wszystkich tekstów\n    result_df.to_csv(checkpoint_file, index=False)\n    \n    return result_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T19:47:26.306958Z","iopub.execute_input":"2024-12-29T19:47:26.307323Z","iopub.status.idle":"2024-12-29T19:47:26.315507Z","shell.execute_reply.started":"2024-12-29T19:47:26.307294Z","shell.execute_reply":"2024-12-29T19:47:26.314611Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df_translated = translate_text(df, batch_size=16, checkpoint_file=\"/kaggle/working/translation_checkpoint.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T19:47:28.311210Z","iopub.execute_input":"2024-12-29T19:47:28.311543Z","iopub.status.idle":"2024-12-29T22:44:13.878044Z","shell.execute_reply.started":"2024-12-29T19:47:28.311513Z","shell.execute_reply":"2024-12-29T22:44:13.876787Z"}},"outputs":[{"name":"stderr","text":"Tłumaczenie tekstów: 1wiersz [00:00,  4.52wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: af\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 957wiersz [02:22,  7.07wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: ar\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 1795wiersz [04:57,  4.26wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Język bg nie jest obsługiwany\nPrzetwarzanie języka: bn\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 2132wiersz [04:59, 88.66wiersz/s] ","output_type":"stream"},{"name":"stdout","text":"Język ca nie jest obsługiwany\nPrzetwarzanie języka: cs\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 4657wiersz [06:59,  5.47wiersz/s] ","output_type":"stream"},{"name":"stdout","text":"Język cy nie jest obsługiwany\nJęzyk da nie jest obsługiwany\nPrzetwarzanie języka: de\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 10124wiersz [20:22,  4.49wiersz/s] ","output_type":"stream"},{"name":"stdout","text":"Język el nie jest obsługiwany\nPrzetwarzanie języka: es\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 19631wiersz [2:56:45,  1.85wiersz/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-1c896fc3162d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_translated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/working/translation_checkpoint.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-01b19314df7e>\u001b[0m in \u001b[0;36mtranslate_text\u001b[0;34m(df, batch_size, checkpoint_file)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;31m# Generowanie tłumaczeń\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 generated_tokens = model.generate(\n\u001b[0m\u001b[1;32m     35\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mencoded_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mforced_bos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang_code_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"en_XX\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Tłumaczymy na angielski\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2064\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   3236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unchanged original behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3238\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1470\u001b[0m                 \u001b[0mdecoder_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift_tokens_right\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1473\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1359\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1215\u001b[0m                 )\n\u001b[1;32m   1216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1218\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;31m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(\n\u001b[0m\u001b[1;32m    571\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer_head_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1888\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T18:13:50.166352Z","iopub.execute_input":"2024-12-29T18:13:50.166668Z","iopub.status.idle":"2024-12-29T18:13:50.176219Z","shell.execute_reply.started":"2024-12-29T18:13:50.166644Z","shell.execute_reply":"2024-12-29T18:13:50.175422Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                              text language translated_text\n0  Empresas: um espetáculo à parte    pt_XX            None\n1          Errei, parei! Que erro!    pt_XX            None\n2                             None    pt_XX            None\n3            Un texte en français.    fr_XX            None\n4    Texto adicional em português.    pt_XX            None\n5           Otro texto en español.    es_XX            None","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>language</th>\n      <th>translated_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Empresas: um espetáculo à parte</td>\n      <td>pt_XX</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Errei, parei! Que erro!</td>\n      <td>pt_XX</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>None</td>\n      <td>pt_XX</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Un texte en français.</td>\n      <td>fr_XX</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Texto adicional em português.</td>\n      <td>pt_XX</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Otro texto en español.</td>\n      <td>es_XX</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# AFTER CHECKPOINT","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/input/checkpoint-for-translation/translation_checkpoint-loaded.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T23:09:42.763023Z","iopub.execute_input":"2024-12-29T23:09:42.763337Z","iopub.status.idle":"2024-12-29T23:09:43.119815Z","shell.execute_reply.started":"2024-12-29T23:09:42.763313Z","shell.execute_reply":"2024-12-29T23:09:43.119072Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df_translated = translate_text(df, batch_size=64, checkpoint_file=\"/kaggle/working/translation_checkpoint.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:59:29.353200Z","iopub.execute_input":"2024-12-29T22:59:29.353502Z","iopub.status.idle":"2024-12-29T23:00:35.407621Z","shell.execute_reply.started":"2024-12-29T22:59:29.353477Z","shell.execute_reply":"2024-12-29T23:00:35.406108Z"}},"outputs":[{"name":"stderr","text":"Tłumaczenie tekstów: 2412wiersz [00:00, 13816.73wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: af\nJęzyk bg nie jest obsługiwany\nJęzyk ca nie jest obsługiwany\nJęzyk cy nie jest obsługiwany\nJęzyk da nie jest obsługiwany\nJęzyk el nie jest obsługiwany\nPrzetwarzanie języka: es\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 4135wiersz [01:05, 62.67wiersz/s]   \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-180538c0c9f6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_translated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/working/translation_checkpoint.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-01b19314df7e>\u001b[0m in \u001b[0;36mtranslate_text\u001b[0;34m(df, batch_size, checkpoint_file)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;31m# Generowanie tłumaczeń\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 generated_tokens = model.generate(\n\u001b[0m\u001b[1;32m     35\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mencoded_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mforced_bos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang_code_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"en_XX\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Tłumaczymy na angielski\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2064\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   3236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unchanged original behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3238\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1470\u001b[0m                 \u001b[0mdecoder_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift_tokens_right\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1473\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1359\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1215\u001b[0m                 )\n\u001b[1;32m   1216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1218\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T22:56:40.245425Z","iopub.execute_input":"2024-12-29T22:56:40.245834Z","iopub.status.idle":"2024-12-29T22:56:40.267441Z","shell.execute_reply.started":"2024-12-29T22:56:40.245799Z","shell.execute_reply":"2024-12-29T22:56:40.266488Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0                                         full_title    views  \\\n0             738  Stories told, stories heard, stories kept | Be...    345.0   \n1            1795  Да върнем смисъла на думите | Maria Laleva | T...   2213.0   \n2            1796  5 хвилин щоб врятувати життя | Галина Алмазова...   1810.0   \n3            1797  Как една непобедима болест те учи да побеждава...   2655.0   \n4            1798  Жити! Творити! Дивуватися! | Олена Загрєбіна (...    283.0   \n...           ...                                                ...      ...   \n55209       70208                 「網紅經濟」是怎麼一回事？ | 育綾 田 | TEDxDongWuU   1746.0   \n55210       70209   「我跟你一樣都是人」，知道「根」在哪裡，我們就不會徬徨 | 知學 田 | TEDxDongWuU  16046.0   \n55211       70210     「法律」猶如阿拉丁神燈，試著了解它，它就會保護你！ | 宇安 陳 | TEDxDongWuU   1956.0   \n55212       70211           不管你移動到哪裡，你都是人 | 江 彥杰 | TEDxChinaMedicalU    564.0   \n55213       70212                        你，就是媒體 | 育寧 張 | TEDxDongWuU   1989.0   \n\n                                date_str        date  year  \\\n0                 6 years ago 16 minutes  2018-12-25  2018   \n1      1 year ago 13 minutes, 31 seconds  2023-12-25  2023   \n2                 7 years ago 21 minutes  2017-12-25  2017   \n3      1 year ago 13 minutes, 19 seconds  2023-12-25  2023   \n4                 5 years ago 16 minutes  2019-12-25  2019   \n...                                  ...         ...   ...   \n55209             4 years ago 22 minutes  2020-12-25  2020   \n55210             4 years ago 22 minutes  2020-12-25  2020   \n55211             4 years ago 17 minutes  2020-12-25  2020   \n55212             7 years ago 19 minutes  2017-12-25  2017   \n55213             9 years ago 22 minutes  2015-12-25  2015   \n\n                                                  title  \\\n0             Stories told, stories heard, stories kept   \n1                           Да върнем смисъла на думите   \n2                          5 хвилин щоб врятувати життя   \n3      Как една непобедима болест те учи да побеждаваш?   \n4                            Жити! Творити! Дивуватися!   \n...                                                 ...   \n55209                                     「網紅經濟」是怎麼一回事？   \n55210                       「我跟你一樣都是人」，知道「根」在哪裡，我們就不會徬徨   \n55211                         「法律」猶如阿拉丁神燈，試著了解它，它就會保護你！   \n55212                                     不管你移動到哪裡，你都是人   \n55213                                            你，就是媒體   \n\n                          speaker                                       event  \\\n0                    Ben McCorkle                            TEDxYearlingRoad   \n1                    Maria Laleva                            TEDxVitoshaSalon   \n2                 Галина Алмазова                                    TEDxKyiv   \n3            Victoria Radoslavova                            TEDxVitoshaSalon   \n4      Олена Загрєбіна (Mura Ura)  Mura Ura (Olena Zagrebina) | TEDxChernihiv   \n...                           ...                                         ...   \n55209                        育綾 田                                 TEDxDongWuU   \n55210                        知學 田                                 TEDxDongWuU   \n55211                        宇安 陳                                 TEDxDongWuU   \n55212                        江 彥杰                           TEDxChinaMedicalU   \n55213                        育寧 張                                 TEDxDongWuU   \n\n      language  original_index  translated_text  \n0           af          103496              NaN  \n1           bg           33376              NaN  \n2           bg          139536              NaN  \n3           bg           33374              NaN  \n4           bg           82129              NaN  \n...        ...             ...              ...  \n55209    zh-tw           67023              NaN  \n55210    zh-tw           67024              NaN  \n55211    zh-tw           67025              NaN  \n55212    zh-tw          131891              NaN  \n55213    zh-tw          168416              NaN  \n\n[55214 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>full_title</th>\n      <th>views</th>\n      <th>date_str</th>\n      <th>date</th>\n      <th>year</th>\n      <th>title</th>\n      <th>speaker</th>\n      <th>event</th>\n      <th>language</th>\n      <th>original_index</th>\n      <th>translated_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>738</td>\n      <td>Stories told, stories heard, stories kept | Be...</td>\n      <td>345.0</td>\n      <td>6 years ago 16 minutes</td>\n      <td>2018-12-25</td>\n      <td>2018</td>\n      <td>Stories told, stories heard, stories kept</td>\n      <td>Ben McCorkle</td>\n      <td>TEDxYearlingRoad</td>\n      <td>af</td>\n      <td>103496</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1795</td>\n      <td>Да върнем смисъла на думите | Maria Laleva | T...</td>\n      <td>2213.0</td>\n      <td>1 year ago 13 minutes, 31 seconds</td>\n      <td>2023-12-25</td>\n      <td>2023</td>\n      <td>Да върнем смисъла на думите</td>\n      <td>Maria Laleva</td>\n      <td>TEDxVitoshaSalon</td>\n      <td>bg</td>\n      <td>33376</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1796</td>\n      <td>5 хвилин щоб врятувати життя | Галина Алмазова...</td>\n      <td>1810.0</td>\n      <td>7 years ago 21 minutes</td>\n      <td>2017-12-25</td>\n      <td>2017</td>\n      <td>5 хвилин щоб врятувати життя</td>\n      <td>Галина Алмазова</td>\n      <td>TEDxKyiv</td>\n      <td>bg</td>\n      <td>139536</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1797</td>\n      <td>Как една непобедима болест те учи да побеждава...</td>\n      <td>2655.0</td>\n      <td>1 year ago 13 minutes, 19 seconds</td>\n      <td>2023-12-25</td>\n      <td>2023</td>\n      <td>Как една непобедима болест те учи да побеждаваш?</td>\n      <td>Victoria Radoslavova</td>\n      <td>TEDxVitoshaSalon</td>\n      <td>bg</td>\n      <td>33374</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1798</td>\n      <td>Жити! Творити! Дивуватися! | Олена Загрєбіна (...</td>\n      <td>283.0</td>\n      <td>5 years ago 16 minutes</td>\n      <td>2019-12-25</td>\n      <td>2019</td>\n      <td>Жити! Творити! Дивуватися!</td>\n      <td>Олена Загрєбіна (Mura Ura)</td>\n      <td>Mura Ura (Olena Zagrebina) | TEDxChernihiv</td>\n      <td>bg</td>\n      <td>82129</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>55209</th>\n      <td>70208</td>\n      <td>「網紅經濟」是怎麼一回事？ | 育綾 田 | TEDxDongWuU</td>\n      <td>1746.0</td>\n      <td>4 years ago 22 minutes</td>\n      <td>2020-12-25</td>\n      <td>2020</td>\n      <td>「網紅經濟」是怎麼一回事？</td>\n      <td>育綾 田</td>\n      <td>TEDxDongWuU</td>\n      <td>zh-tw</td>\n      <td>67023</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>55210</th>\n      <td>70209</td>\n      <td>「我跟你一樣都是人」，知道「根」在哪裡，我們就不會徬徨 | 知學 田 | TEDxDongWuU</td>\n      <td>16046.0</td>\n      <td>4 years ago 22 minutes</td>\n      <td>2020-12-25</td>\n      <td>2020</td>\n      <td>「我跟你一樣都是人」，知道「根」在哪裡，我們就不會徬徨</td>\n      <td>知學 田</td>\n      <td>TEDxDongWuU</td>\n      <td>zh-tw</td>\n      <td>67024</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>55211</th>\n      <td>70210</td>\n      <td>「法律」猶如阿拉丁神燈，試著了解它，它就會保護你！ | 宇安 陳 | TEDxDongWuU</td>\n      <td>1956.0</td>\n      <td>4 years ago 17 minutes</td>\n      <td>2020-12-25</td>\n      <td>2020</td>\n      <td>「法律」猶如阿拉丁神燈，試著了解它，它就會保護你！</td>\n      <td>宇安 陳</td>\n      <td>TEDxDongWuU</td>\n      <td>zh-tw</td>\n      <td>67025</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>55212</th>\n      <td>70211</td>\n      <td>不管你移動到哪裡，你都是人 | 江 彥杰 | TEDxChinaMedicalU</td>\n      <td>564.0</td>\n      <td>7 years ago 19 minutes</td>\n      <td>2017-12-25</td>\n      <td>2017</td>\n      <td>不管你移動到哪裡，你都是人</td>\n      <td>江 彥杰</td>\n      <td>TEDxChinaMedicalU</td>\n      <td>zh-tw</td>\n      <td>131891</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>55213</th>\n      <td>70212</td>\n      <td>你，就是媒體 | 育寧 張 | TEDxDongWuU</td>\n      <td>1989.0</td>\n      <td>9 years ago 22 minutes</td>\n      <td>2015-12-25</td>\n      <td>2015</td>\n      <td>你，就是媒體</td>\n      <td>育寧 張</td>\n      <td>TEDxDongWuU</td>\n      <td>zh-tw</td>\n      <td>168416</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>55214 rows × 12 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Added batching","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\n\ndef translate_text(df, batch_size=8, checkpoint_file=\"translation_checkpoint.csv\"):\n    translated_texts = [None] * len(df)  # Lista na przetłumaczone teksty\n    language_counter = 0  # Licznik do zapisywania checkpointu co 5000 rekordów\n\n    # Zapisz oryginalne indeksy\n    df = df.copy()  # Upewniamy się, że pracujemy na kopii DataFrame\n    df.loc[:, 'original_index'] = df.index\n\n    # Sortowanie danych według języka\n    df_sorted = df.sort_values(by='language').reset_index(drop=True)\n\n    # Przetwarzanie tekstów w batchach\n    current_language = None\n    batch_texts = []\n    batch_indices = []\n\n    for idx, row in tqdm(df_sorted.iterrows(), desc=\"Tłumaczenie tekstów\", unit=\"wiersz\"):\n        language_code = row['language']\n        if language_code != current_language:\n            if batch_texts:\n                # Przetwarzanie batcha\n                encoded_texts = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n                generated_tokens = model.generate(\n                    **encoded_texts,\n                    forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]\n                )\n                translated_batch = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n                for i, translated_text in enumerate(translated_batch):\n                    translated_texts[batch_indices[i]] = translated_text\n\n                batch_texts = []\n                batch_indices = []\n\n            current_language = language_code\n            if language_code in language_dict:\n                print(f\"Przetwarzanie języka: {language_code}\")\n            else:\n                print(f\"Język {language_code} nie jest obsługiwany\")\n\n        if language_code in language_dict:\n            tokenizer.src_lang = language_dict[language_code]\n            text = row['title']\n            if isinstance(text, str) and text.strip() != \"\":\n                batch_texts.append(text)\n                batch_indices.append(idx)\n\n                if len(batch_texts) == batch_size:\n                    encoded_texts = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n                    generated_tokens = model.generate(\n                        **encoded_texts,\n                        forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]\n                    )\n                    translated_batch = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n                    for i, translated_text in enumerate(translated_batch):\n                        translated_texts[batch_indices[i]] = translated_text\n\n                    batch_texts = []\n                    batch_indices = []\n\n            else:\n                translated_texts[idx] = None\n\n            language_counter += 1\n            if language_counter % 5000 == 0:\n                checkpoint_df = df_sorted.copy()\n                checkpoint_df['translated_text'] = translated_texts\n                checkpoint_df.to_csv(checkpoint_file, index=False)\n        else:\n            translated_texts[idx] = None\n\n    if batch_texts:\n        encoded_texts = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n        generated_tokens = model.generate(\n            **encoded_texts,\n            forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]\n        )\n        translated_batch = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n        for i, translated_text in enumerate(translated_batch):\n            translated_texts[batch_indices[i]] = translated_text\n\n    df_sorted.loc[:, 'translated_text'] = translated_texts\n    result_df = df_sorted.sort_values(by='original_index').drop(columns=['original_index']).reset_index(drop=True)\n    result_df.to_csv(checkpoint_file, index=False)\n    \n    return result_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T11:36:56.567781Z","iopub.execute_input":"2024-12-30T11:36:56.567995Z","iopub.status.idle":"2024-12-30T11:36:56.578117Z","shell.execute_reply.started":"2024-12-30T11:36:56.567976Z","shell.execute_reply":"2024-12-30T11:36:56.577311Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df_translated = translate_text(df, batch_size=32, checkpoint_file=\"/kaggle/working/translation2_checkpoint.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T23:09:48.923032Z","iopub.execute_input":"2024-12-29T23:09:48.923329Z","iopub.status.idle":"2024-12-30T00:25:13.599851Z","shell.execute_reply.started":"2024-12-29T23:09:48.923305Z","shell.execute_reply":"2024-12-30T00:25:13.598500Z"}},"outputs":[{"name":"stderr","text":"Tłumaczenie tekstów: 0wiersz [00:00, ?wiersz/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: af\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 2435wiersz [00:01, 3023.06wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Język bg nie jest obsługiwany\nJęzyk ca nie jest obsługiwany\nJęzyk cy nie jest obsługiwany\nJęzyk da nie jest obsługiwany\nJęzyk el nie jest obsługiwany\nPrzetwarzanie języka: es\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 9794wiersz [51:49,  1.83wiersz/s]  ","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: et\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 10469wiersz [52:27, 14.33wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: fa\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 10534wiersz [52:28, 16.44wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: fi\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 10907wiersz [52:48, 20.62wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: fr\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 18702wiersz [59:22, 18.65wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: he\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 18706wiersz [59:23, 15.12wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: hi\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 18714wiersz [59:23, 15.73wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: hr\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 19399wiersz [1:00:04, 17.64wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Język hu nie jest obsługiwany\nPrzetwarzanie języka: id\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 21797wiersz [1:01:36, 17.57wiersz/s] ","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: it\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 28291wiersz [1:06:36, 23.72wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: ja\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 29122wiersz [1:07:28, 15.72wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Język kn nie jest obsługiwany\nPrzetwarzanie języka: ko\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 30689wiersz [1:09:02, 18.92wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: lt\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 30919wiersz [1:09:15, 16.94wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: lv\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 30991wiersz [1:09:19, 18.50wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: mk\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 31053wiersz [1:09:22, 20.45wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: mr\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 31056wiersz [1:09:22, 19.23wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: ne\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 31058wiersz [1:09:22, 18.27wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: nl\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 32615wiersz [1:10:46, 16.95wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Język no nie jest obsługiwany\nPrzetwarzanie języka: pl\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 35101wiersz [1:12:16, 17.64wiersz/s] ","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: pt\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 38619wiersz [1:15:24,  8.54wiersz/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-53daa2af97d7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_translated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/working/translation2_checkpoint.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-d3a932823fa2>\u001b[0m in \u001b[0;36mtranslate_text\u001b[0;34m(df, batch_size, checkpoint_file)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_texts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0mencoded_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     generated_tokens = model.generate(\n\u001b[0m\u001b[1;32m     53\u001b[0m                         \u001b[0;34m**\u001b[0m\u001b[0mencoded_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                         \u001b[0mforced_bos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang_code_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"en_XX\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2064\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m             \u001b[0;31m# stateless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m             beam_outputs = beam_scorer.process(\n\u001b[0m\u001b[1;32m   3301\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m                 \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/beam_search.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id, beam_indices, group_index, decoder_prompt_len)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mbatch_group_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_beam_groups\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgroup_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_group_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_beams\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_beam_hyps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_group_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Batch can only be done if at least {self.num_beams} beams have been generated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meos_token_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpad_token_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/beam_search.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    946\u001b[0m             )\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m         \"\"\"\n\u001b[1;32m    950\u001b[0m         \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mhypotheses\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/input/translation-checkpoint2/translation2_checkpoint-loaded.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T11:36:56.578880Z","iopub.execute_input":"2024-12-30T11:36:56.579102Z","iopub.status.idle":"2024-12-30T11:36:56.797706Z","shell.execute_reply.started":"2024-12-30T11:36:56.579073Z","shell.execute_reply":"2024-12-30T11:36:56.796982Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T11:36:56.798639Z","iopub.execute_input":"2024-12-30T11:36:56.799049Z","iopub.status.idle":"2024-12-30T11:36:56.823360Z","shell.execute_reply.started":"2024-12-30T11:36:56.799014Z","shell.execute_reply":"2024-12-30T11:36:56.822592Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0.1  Unnamed: 0  \\\n0                 0         738   \n1                 1        2005   \n2                 2        2004   \n3                 3        2003   \n4                 4        2002   \n...             ...         ...   \n25219         25219       69960   \n25220         25220       69959   \n25221         25221       69958   \n25222         25222       69967   \n25223         25223       70212   \n\n                                              full_title   views  \\\n0      Stories told, stories heard, stories kept | Be...   345.0   \n1      Звездната система и следващото поколение в шоу...  6711.0   \n2      Защо не?възможната промяна в образованието | D...   874.0   \n3      Родители от следващо поколение | Ася Демирева ...  4382.0   \n4      Не-обещание и не-изпълнение | Еленко Еленков |...  7935.0   \n...                                                  ...     ...   \n25219     人人都可以是大藝術家 | 謝昕璇 | Hsin-Hsuan Hsieh | TEDxNDHU  1550.0   \n25220               自信才是最好的時尚單品 | 圈 入準 | TEDxChungChengU  1037.0   \n25221                「嘿！多久沒到書店走走啦？」 | 王 政中 | TEDxDongWuU   124.0   \n25222    那些年。孩子與動物教我的事 | 呂 軍逸 | TEDxProvidenceUniversity   754.0   \n25223                        你，就是媒體 | 育寧 張 | TEDxDongWuU  1989.0   \n\n                               date_str                 date  year  \\\n0                6 years ago 16 minutes           2018-12-25  2018   \n1                2 years ago 22 minutes           2022-12-25  2022   \n2      6 years ago 13 minutes, 1 second           2018-12-25  2018   \n3                2 years ago 17 minutes           2022-12-25  2022   \n4               10 years ago 17 minutes           2014-12-25  2014   \n...                                 ...                  ...   ...   \n25219            7 years ago 17 minutes           2017-12-25  2017   \n25220            2 years ago 19 minutes           2022-12-25  2022   \n25221           7 months ago 21 minutes  2024-05-25 00:00:00  2024   \n25222            3 years ago 24 minutes           2021-12-25  2021   \n25223            9 years ago 22 minutes           2015-12-25  2015   \n\n                                                   title              speaker  \\\n0              Stories told, stories heard, stories kept         Ben McCorkle   \n1      Звездната система и следващото поколение в шоу...  Магърдич Халваджиян   \n2             Защо не?възможната промяна в образованието   Dimitrina Dokimova   \n3                         Родители от следващо поколение         Ася Демирева   \n4                            Не-обещание и не-изпълнение       Еленко Еленков   \n...                                                  ...                  ...   \n25219                                         人人都可以是大藝術家                  謝昕璇   \n25220                                        自信才是最好的時尚單品                 圈 入準   \n25221                                     「嘿！多久沒到書店走走啦？」                 王 政中   \n25222                                      那些年。孩子與動物教我的事                 呂 軍逸   \n25223                                             你，就是媒體                 育寧 張   \n\n                             event language  original_index  translated_text  \n0                 TEDxYearlingRoad       af               0              NaN  \n1                      TEDxMladost       bg             211              NaN  \n2                TEDxPrimorskiPark       bg             210              NaN  \n3                      TEDxMladost       bg             209              NaN  \n4                           TEDxBG       bg             208              NaN  \n...                            ...      ...             ...              ...  \n25219  Hsin-Hsuan Hsieh | TEDxNDHU    zh-tw           54961              NaN  \n25220              TEDxChungChengU    zh-tw           54960              NaN  \n25221                  TEDxDongWuU    zh-tw           54959              NaN  \n25222     TEDxProvidenceUniversity    zh-tw           54968              NaN  \n25223                  TEDxDongWuU    zh-tw           55213              NaN  \n\n[25224 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>full_title</th>\n      <th>views</th>\n      <th>date_str</th>\n      <th>date</th>\n      <th>year</th>\n      <th>title</th>\n      <th>speaker</th>\n      <th>event</th>\n      <th>language</th>\n      <th>original_index</th>\n      <th>translated_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>738</td>\n      <td>Stories told, stories heard, stories kept | Be...</td>\n      <td>345.0</td>\n      <td>6 years ago 16 minutes</td>\n      <td>2018-12-25</td>\n      <td>2018</td>\n      <td>Stories told, stories heard, stories kept</td>\n      <td>Ben McCorkle</td>\n      <td>TEDxYearlingRoad</td>\n      <td>af</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2005</td>\n      <td>Звездната система и следващото поколение в шоу...</td>\n      <td>6711.0</td>\n      <td>2 years ago 22 minutes</td>\n      <td>2022-12-25</td>\n      <td>2022</td>\n      <td>Звездната система и следващото поколение в шоу...</td>\n      <td>Магърдич Халваджиян</td>\n      <td>TEDxMladost</td>\n      <td>bg</td>\n      <td>211</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2004</td>\n      <td>Защо не?възможната промяна в образованието | D...</td>\n      <td>874.0</td>\n      <td>6 years ago 13 minutes, 1 second</td>\n      <td>2018-12-25</td>\n      <td>2018</td>\n      <td>Защо не?възможната промяна в образованието</td>\n      <td>Dimitrina Dokimova</td>\n      <td>TEDxPrimorskiPark</td>\n      <td>bg</td>\n      <td>210</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2003</td>\n      <td>Родители от следващо поколение | Ася Демирева ...</td>\n      <td>4382.0</td>\n      <td>2 years ago 17 minutes</td>\n      <td>2022-12-25</td>\n      <td>2022</td>\n      <td>Родители от следващо поколение</td>\n      <td>Ася Демирева</td>\n      <td>TEDxMladost</td>\n      <td>bg</td>\n      <td>209</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2002</td>\n      <td>Не-обещание и не-изпълнение | Еленко Еленков |...</td>\n      <td>7935.0</td>\n      <td>10 years ago 17 minutes</td>\n      <td>2014-12-25</td>\n      <td>2014</td>\n      <td>Не-обещание и не-изпълнение</td>\n      <td>Еленко Еленков</td>\n      <td>TEDxBG</td>\n      <td>bg</td>\n      <td>208</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25219</th>\n      <td>25219</td>\n      <td>69960</td>\n      <td>人人都可以是大藝術家 | 謝昕璇 | Hsin-Hsuan Hsieh | TEDxNDHU</td>\n      <td>1550.0</td>\n      <td>7 years ago 17 minutes</td>\n      <td>2017-12-25</td>\n      <td>2017</td>\n      <td>人人都可以是大藝術家</td>\n      <td>謝昕璇</td>\n      <td>Hsin-Hsuan Hsieh | TEDxNDHU</td>\n      <td>zh-tw</td>\n      <td>54961</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25220</th>\n      <td>25220</td>\n      <td>69959</td>\n      <td>自信才是最好的時尚單品 | 圈 入準 | TEDxChungChengU</td>\n      <td>1037.0</td>\n      <td>2 years ago 19 minutes</td>\n      <td>2022-12-25</td>\n      <td>2022</td>\n      <td>自信才是最好的時尚單品</td>\n      <td>圈 入準</td>\n      <td>TEDxChungChengU</td>\n      <td>zh-tw</td>\n      <td>54960</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25221</th>\n      <td>25221</td>\n      <td>69958</td>\n      <td>「嘿！多久沒到書店走走啦？」 | 王 政中 | TEDxDongWuU</td>\n      <td>124.0</td>\n      <td>7 months ago 21 minutes</td>\n      <td>2024-05-25 00:00:00</td>\n      <td>2024</td>\n      <td>「嘿！多久沒到書店走走啦？」</td>\n      <td>王 政中</td>\n      <td>TEDxDongWuU</td>\n      <td>zh-tw</td>\n      <td>54959</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25222</th>\n      <td>25222</td>\n      <td>69967</td>\n      <td>那些年。孩子與動物教我的事 | 呂 軍逸 | TEDxProvidenceUniversity</td>\n      <td>754.0</td>\n      <td>3 years ago 24 minutes</td>\n      <td>2021-12-25</td>\n      <td>2021</td>\n      <td>那些年。孩子與動物教我的事</td>\n      <td>呂 軍逸</td>\n      <td>TEDxProvidenceUniversity</td>\n      <td>zh-tw</td>\n      <td>54968</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25223</th>\n      <td>25223</td>\n      <td>70212</td>\n      <td>你，就是媒體 | 育寧 張 | TEDxDongWuU</td>\n      <td>1989.0</td>\n      <td>9 years ago 22 minutes</td>\n      <td>2015-12-25</td>\n      <td>2015</td>\n      <td>你，就是媒體</td>\n      <td>育寧 張</td>\n      <td>TEDxDongWuU</td>\n      <td>zh-tw</td>\n      <td>55213</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>25224 rows × 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df_translated = translate_text(df, batch_size=24, checkpoint_file=\"/kaggle/working/translation3_checkpoint.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T11:36:56.824052Z","iopub.execute_input":"2024-12-30T11:36:56.824343Z","iopub.status.idle":"2024-12-30T12:06:11.354478Z","shell.execute_reply.started":"2024-12-30T11:36:56.824304Z","shell.execute_reply":"2024-12-30T12:06:11.353506Z"}},"outputs":[{"name":"stderr","text":"Tłumaczenie tekstów: 0wiersz [00:00, ?wiersz/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: af\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 4796wiersz [00:00, 7606.00wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Język bg nie jest obsługiwany\nJęzyk ca nie jest obsługiwany\nJęzyk cy nie jest obsługiwany\nJęzyk da nie jest obsługiwany\nJęzyk el nie jest obsługiwany\nJęzyk hu nie jest obsługiwany\nJęzyk kn nie jest obsługiwany\nJęzyk no nie jest obsługiwany\nPrzetwarzanie języka: pt\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 12661wiersz [05:37, 23.61wiersz/s] ","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: ro\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 14696wiersz [06:59, 27.45wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: ru\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 15950wiersz [07:54, 25.31wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Język sk nie jest obsługiwany\nPrzetwarzanie języka: sl\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 16978wiersz [08:28, 19.41wiersz/s] ","output_type":"stream"},{"name":"stdout","text":"Język so nie jest obsługiwany\nJęzyk sq nie jest obsługiwany\nPrzetwarzanie języka: sv\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 18054wiersz [08:51, 20.42wiersz/s] ","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: sw\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 18434wiersz [12:02,  2.07wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: ta\nPrzetwarzanie języka: th\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 18936wiersz [12:20, 26.81wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: tl\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 20620wiersz [26:41,  1.87wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: tr\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 23302wiersz [28:30, 22.24wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: uk\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 23685wiersz [28:50, 18.68wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Język unknown nie jest obsługiwany\nPrzetwarzanie języka: ur\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 23745wiersz [28:51, 34.20wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Przetwarzanie języka: vi\n","output_type":"stream"},{"name":"stderr","text":"Tłumaczenie tekstów: 25224wiersz [29:14, 14.38wiersz/s]","output_type":"stream"},{"name":"stdout","text":"Język zh-cn nie jest obsługiwany\nJęzyk zh-tw nie jest obsługiwany\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8}]}