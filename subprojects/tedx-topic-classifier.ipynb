{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10318637,"sourceType":"datasetVersion","datasetId":6388404},{"sourceId":10322339,"sourceType":"datasetVersion","datasetId":6391069},{"sourceId":10334690,"sourceType":"datasetVersion","datasetId":6399204}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T13:35:16.506550Z","iopub.execute_input":"2024-12-30T13:35:16.506826Z","iopub.status.idle":"2024-12-30T13:35:16.801456Z","shell.execute_reply.started":"2024-12-30T13:35:16.506803Z","shell.execute_reply":"2024-12-30T13:35:16.800781Z"},"editable":false},"outputs":[{"name":"stdout","text":"/kaggle/input/tedy-with-lang/tedx_videos_extended_with_lang.csv\n/kaggle/input/tedx-with-lang-translated/tedx_videos_extended_with_lang_translated.csv\n/kaggle/input/terdx-finetuning/topics_train.csv\n/kaggle/input/terdx-finetuning/sentiment_test.csv\n/kaggle/input/terdx-finetuning/topics_test.csv\n/kaggle/input/terdx-finetuning/sentiment_train.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nHF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\nWANDB_API = user_secrets.get_secret(\"WANDB_API\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:24:44.853810Z","iopub.execute_input":"2024-12-28T14:24:44.854133Z","iopub.status.idle":"2024-12-28T14:24:45.125478Z","shell.execute_reply.started":"2024-12-28T14:24:44.854107Z","shell.execute_reply":"2024-12-28T14:24:45.124801Z"},"editable":false},"outputs":[],"execution_count":25},{"cell_type":"code","source":"!pip install --upgrade datasets transformers evaluate sentencepiece accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:52:40.474889Z","iopub.status.idle":"2024-12-28T13:52:40.475143Z","shell.execute_reply":"2024-12-28T13:52:40.475042Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ntags = pd.read_csv('/kaggle/input/terdx-finetuning/topics_train.csv')\ntags","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:52:40.485858Z","iopub.execute_input":"2024-12-28T13:52:40.486085Z","iopub.status.idle":"2024-12-28T13:52:40.813107Z","shell.execute_reply.started":"2024-12-28T13:52:40.486065Z","shell.execute_reply":"2024-12-28T13:52:40.812311Z"},"editable":false},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                  title        best_tag\n0     I was held hostage for 317 days. Here's what I...   global issues\n1     Planet City -- a sci-fi vision of an astonishi...  sustainability\n2                       Progress is not a zero-sum game   global issues\n3     How I'm making bricks out of ashes and rubble ...  sustainability\n4                    How vultures can help solve crimes          nature\n...                                                 ...             ...\n5059                                  Why do we hiccup?          health\n5060                                Why videos go viral   entertainment\n5061                            A primer on 3D printing      technology\n5062                 Building a dinosaur from a chicken         science\n5063  A transparent, easy way for smallholder farmer...  sustainability\n\n[5064 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>best_tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I was held hostage for 317 days. Here's what I...</td>\n      <td>global issues</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Planet City -- a sci-fi vision of an astonishi...</td>\n      <td>sustainability</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Progress is not a zero-sum game</td>\n      <td>global issues</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How I'm making bricks out of ashes and rubble ...</td>\n      <td>sustainability</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How vultures can help solve crimes</td>\n      <td>nature</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5059</th>\n      <td>Why do we hiccup?</td>\n      <td>health</td>\n    </tr>\n    <tr>\n      <th>5060</th>\n      <td>Why videos go viral</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>5061</th>\n      <td>A primer on 3D printing</td>\n      <td>technology</td>\n    </tr>\n    <tr>\n      <th>5062</th>\n      <td>Building a dinosaur from a chicken</td>\n      <td>science</td>\n    </tr>\n    <tr>\n      <th>5063</th>\n      <td>A transparent, easy way for smallholder farmer...</td>\n      <td>sustainability</td>\n    </tr>\n  </tbody>\n</table>\n<p>5064 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\n\nfile_dict = {\n  \"train\" : \"/kaggle/input/terdx-finetuning/topics_train.csv\",\n  \"test\" : \"/kaggle/input/terdx-finetuning/topics_test.csv\"\n}\n\ndataset = load_dataset(\n  'csv',\n  data_files=file_dict,\n  delimiter=',',\n  column_names=['title', 'best_tag'],\n  skiprows=1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:52:40.814079Z","iopub.execute_input":"2024-12-28T13:52:40.814334Z","iopub.status.idle":"2024-12-28T13:52:42.449275Z","shell.execute_reply.started":"2024-12-28T13:52:40.814313Z","shell.execute_reply":"2024-12-28T13:52:42.448445Z"},"editable":false},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd757f118d1f4b0b802813d473de8a49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baf609093c5644ef854d0dedf25c9c34"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Extract all unique tags from the 'tag' column\nall_tags = []\nfor split in dataset:  # Iterate over 'train' and 'test' splits\n    for example in dataset[split]:\n        tags = example['best_tag'].split(', ')\n        all_tags.extend(tags)\nclasses = sorted(list(set(all_tags)))\n\nclasses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:52:42.450610Z","iopub.execute_input":"2024-12-28T13:52:42.450945Z","iopub.status.idle":"2024-12-28T13:52:42.595122Z","shell.execute_reply.started":"2024-12-28T13:52:42.450924Z","shell.execute_reply":"2024-12-28T13:52:42.594456Z"},"editable":false},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['AI',\n 'art',\n 'business',\n 'climate change',\n 'communication',\n 'creativity',\n 'culture',\n 'design',\n 'economics',\n 'education',\n 'entertainment',\n 'environment',\n 'food',\n 'gender',\n 'global issues',\n 'health',\n 'history',\n 'humanity',\n 'innovation',\n 'literature',\n 'mental health',\n 'music',\n 'nature',\n 'personal growth',\n 'politics',\n 'psychology',\n 'science',\n 'social change',\n 'storytelling',\n 'sustainability',\n 'technology',\n 'work']"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Create mappings\nclass2id = {class_: id for id, class_ in enumerate(classes)}\nid2class = {id: class_ for class_, id in class2id.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:52:42.596108Z","iopub.execute_input":"2024-12-28T13:52:42.596410Z","iopub.status.idle":"2024-12-28T13:52:42.600173Z","shell.execute_reply.started":"2024-12-28T13:52:42.596387Z","shell.execute_reply":"2024-12-28T13:52:42.599394Z"},"editable":false},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(class2id)\nprint(id2class)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:52:42.601137Z","iopub.execute_input":"2024-12-28T13:52:42.601437Z","iopub.status.idle":"2024-12-28T13:52:42.612606Z","shell.execute_reply.started":"2024-12-28T13:52:42.601407Z","shell.execute_reply":"2024-12-28T13:52:42.612004Z"},"editable":false},"outputs":[{"name":"stdout","text":"{'AI': 0, 'art': 1, 'business': 2, 'climate change': 3, 'communication': 4, 'creativity': 5, 'culture': 6, 'design': 7, 'economics': 8, 'education': 9, 'entertainment': 10, 'environment': 11, 'food': 12, 'gender': 13, 'global issues': 14, 'health': 15, 'history': 16, 'humanity': 17, 'innovation': 18, 'literature': 19, 'mental health': 20, 'music': 21, 'nature': 22, 'personal growth': 23, 'politics': 24, 'psychology': 25, 'science': 26, 'social change': 27, 'storytelling': 28, 'sustainability': 29, 'technology': 30, 'work': 31}\n{0: 'AI', 1: 'art', 2: 'business', 3: 'climate change', 4: 'communication', 5: 'creativity', 6: 'culture', 7: 'design', 8: 'economics', 9: 'education', 10: 'entertainment', 11: 'environment', 12: 'food', 13: 'gender', 14: 'global issues', 15: 'health', 16: 'history', 17: 'humanity', 18: 'innovation', 19: 'literature', 20: 'mental health', 21: 'music', 22: 'nature', 23: 'personal growth', 24: 'politics', 25: 'psychology', 26: 'science', 27: 'social change', 28: 'storytelling', 29: 'sustainability', 30: 'technology', 31: 'work'}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_path = 'facebook/bart-large-mnli'\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:52:42.613352Z","iopub.execute_input":"2024-12-28T13:52:42.613559Z","iopub.status.idle":"2024-12-28T13:52:47.449617Z","shell.execute_reply.started":"2024-12-28T13:52:42.613532Z","shell.execute_reply":"2024-12-28T13:52:47.448600Z"},"editable":false},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7057c929faf8434192c9d90e82cf8dca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c0b49fd09734fc9b1dbf7df964ad59f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"159644da28c2413f907fc7ccc9352565"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e4c59efd74940b398ae518a017aee61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f613a585056d4807b8e086ea8047bafb"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def preprocess_function(example):\n   text = example['title']\n   all_labels = example['best_tag'].split(', ')\n   labels = [0. for i in range(len(classes))]\n   for label in all_labels:\n       label_id = class2id[label]\n       labels[label_id] = 1.\n\n   example = tokenizer(text, truncation=True)\n   example['best_tag'] = labels\n   return example\n\ntokenized_dataset = dataset.map(preprocess_function)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:52:47.450427Z","iopub.execute_input":"2024-12-28T13:52:47.450753Z","iopub.status.idle":"2024-12-28T13:52:48.582577Z","shell.execute_reply.started":"2024-12-28T13:52:47.450729Z","shell.execute_reply":"2024-12-28T13:52:48.581671Z"},"editable":false},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5064 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d756e5fd90549f8a6aff06acd57e92d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1266 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d4f1ed52e754284afd490c2f98461ca"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:52:48.584286Z","iopub.execute_input":"2024-12-28T13:52:48.584513Z","iopub.status.idle":"2024-12-28T13:52:55.897089Z","shell.execute_reply.started":"2024-12-28T13:52:48.584494Z","shell.execute_reply":"2024-12-28T13:52:55.896420Z"},"editable":false},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\nfrom transformers import EvalPrediction\nimport torch\n\n# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\ndef multi_label_metrics(predictions, labels, threshold=0.5):\n    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n    sigmoid = torch.nn.Sigmoid()\n    probs = sigmoid(torch.Tensor(predictions))\n    # next, use threshold to turn them into integer predictions\n    y_pred = np.zeros(probs.shape)\n    y_pred[np.where(probs >= threshold)] = 1\n    # finally, compute metrics\n    y_true = labels\n    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n    accuracy = accuracy_score(y_true, y_pred)\n    # return as dictionary\n    metrics = {'f1': f1_micro_average,\n               'roc_auc': roc_auc,\n               'accuracy': accuracy}\n    return metrics\n\ndef compute_metrics(p: EvalPrediction):\n    preds = p.predictions[0] if isinstance(p.predictions,\n            tuple) else p.predictions\n    result = multi_label_metrics(\n        predictions=preds,\n        labels=p.label_ids)\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:52:55.898063Z","iopub.execute_input":"2024-12-28T13:52:55.898648Z","iopub.status.idle":"2024-12-28T13:52:55.908053Z","shell.execute_reply.started":"2024-12-28T13:52:55.898624Z","shell.execute_reply":"2024-12-28T13:52:55.907178Z"},"editable":false},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_path, num_labels=len(classes),\n    id2label=id2class, label2id=class2id,\n    problem_type = \"multi_label_classification\", \n    ignore_mismatched_sizes=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:52:55.908815Z","iopub.execute_input":"2024-12-28T13:52:55.909005Z","iopub.status.idle":"2024-12-28T13:53:10.362842Z","shell.execute_reply.started":"2024-12-28T13:52:55.908987Z","shell.execute_reply":"2024-12-28T13:53:10.361786Z"},"editable":false},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f05d31fe5c9448f8ab588ebc0e3dc61"}},"metadata":{}},{"name":"stderr","text":"Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large-mnli and are newly initialized because the shapes did not match:\n- classification_head.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([32]) in the model instantiated\n- classification_head.out_proj.weight: found shape torch.Size([3, 1024]) in the checkpoint and torch.Size([32, 1024]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import wandb\nwandb.login(key=WANDB_API)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:54:40.627898Z","iopub.execute_input":"2024-12-28T13:54:40.628263Z","iopub.status.idle":"2024-12-28T13:54:46.754038Z","shell.execute_reply.started":"2024-12-28T13:54:40.628225Z","shell.execute_reply":"2024-12-28T13:54:46.753398Z"},"editable":false},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mczarnybaranie1\u001b[0m (\u001b[33mczarnybaranie1-sgh-warsaw-school-of-economics\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import os\n# set the wandb project where this run will be logged\nos.environ[\"WANDB_PROJECT\"]=\"tedx_topic_classification\"\n\n# save your trained model checkpoint to wandb\nos.environ[\"WANDB_LOG_MODEL\"]=\"checkpoint\"\n\n# turn off watch to log faster\nos.environ[\"WANDB_WATCH\"]=\"false\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:54:46.755077Z","iopub.execute_input":"2024-12-28T13:54:46.755597Z","iopub.status.idle":"2024-12-28T13:54:46.760046Z","shell.execute_reply.started":"2024-12-28T13:54:46.755574Z","shell.execute_reply":"2024-12-28T13:54:46.759278Z"},"editable":false},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Rename columns to text and labels (needed for model setup)\ntokenized_dataset = tokenized_dataset.rename_column(\"title\", \"text\")\ntokenized_dataset = tokenized_dataset.rename_column(\"best_tag\", \"labels\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:54:49.028511Z","iopub.execute_input":"2024-12-28T13:54:49.028804Z","iopub.status.idle":"2024-12-28T13:54:49.038997Z","shell.execute_reply.started":"2024-12-28T13:54:49.028781Z","shell.execute_reply":"2024-12-28T13:54:49.038119Z"},"editable":false},"outputs":[],"execution_count":18},{"cell_type":"code","source":"training_args = TrainingArguments(\n\n   output_dir=\"/kaggle/working/topic_classifier\",\n   learning_rate=2e-5,\n   per_device_train_batch_size=3,\n   per_device_eval_batch_size=3,\n   num_train_epochs=2,\n   weight_decay=0.01,\n   evaluation_strategy=\"steps\",\n   eval_steps=100,\n   save_strategy=\"steps\",\n   save_steps=500,\n   load_best_model_at_end=True,\n)\n\ntrainer = Trainer(\n\n   model=model,\n   args=training_args,\n   train_dataset=tokenized_dataset[\"train\"],\n   eval_dataset=tokenized_dataset[\"test\"],\n   tokenizer=tokenizer,\n   data_collator=data_collator,\n   compute_metrics=compute_metrics,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T11:31:19.071408Z","iopub.execute_input":"2024-12-28T11:31:19.071731Z","iopub.status.idle":"2024-12-28T11:31:20.142383Z","shell.execute_reply.started":"2024-12-28T11:31:19.071706Z","shell.execute_reply":"2024-12-28T11:31:20.141702Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T11:31:44.134278Z","iopub.execute_input":"2024-12-28T11:31:44.134659Z","iopub.status.idle":"2024-12-28T11:31:44.140282Z","shell.execute_reply.started":"2024-12-28T11:31:44.134627Z","shell.execute_reply":"2024-12-28T11:31:44.139328Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T11:31:53.887000Z","iopub.execute_input":"2024-12-28T11:31:53.887312Z","iopub.status.idle":"2024-12-28T12:04:02.639847Z","shell.execute_reply.started":"2024-12-28T11:31:53.887288Z","shell.execute_reply":"2024-12-28T12:04:02.638820Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import PyTorchModelHubMixin\nmodel_name = \"/kaggle/working/topic_classifier/checkpoint-1500\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\nmodel.push_to_hub(\"CzarnyBaranie/topic-classifier-checkpoint-1500\",private=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T12:25:51.873627Z","iopub.execute_input":"2024-12-28T12:25:51.873954Z","iopub.status.idle":"2024-12-28T12:26:50.264492Z","shell.execute_reply.started":"2024-12-28T12:25:51.873931Z","shell.execute_reply":"2024-12-28T12:26:50.263754Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"###### Usuwanie folderu - KLIKNIJ TYLKO JEDEN RAZ!\nimport shutil\nshutil.rmtree(\"/kaggle/working/topic_classifier/checkpoint-1688\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T12:30:25.235974Z","iopub.execute_input":"2024-12-28T12:30:25.236325Z","iopub.status.idle":"2024-12-28T12:30:25.578381Z","shell.execute_reply.started":"2024-12-28T12:30:25.236294Z","shell.execute_reply":"2024-12-28T12:30:25.577684Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = TrainingArguments(\n\n   output_dir=\"/kaggle/working/topic_classifier\",\n   learning_rate=2e-5,\n   per_device_train_batch_size=3,\n   per_device_eval_batch_size=3,\n   num_train_epochs=4,\n   weight_decay=0.01,\n   evaluation_strategy=\"steps\",\n   eval_steps=100,\n   save_strategy=\"steps\",\n   save_steps=500,\n   load_best_model_at_end=True,\n   save_total_limit=4, \n)\n\ntrainer = Trainer(\n\n   model=model,\n   args=training_args,\n   train_dataset=tokenized_dataset[\"train\"],\n   eval_dataset=tokenized_dataset[\"test\"],\n   tokenizer=tokenizer,\n   data_collator=data_collator,\n   compute_metrics=compute_metrics,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T12:32:00.905243Z","iopub.execute_input":"2024-12-28T12:32:00.905639Z","iopub.status.idle":"2024-12-28T12:32:01.463051Z","shell.execute_reply.started":"2024-12-28T12:32:00.905587Z","shell.execute_reply":"2024-12-28T12:32:01.462330Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Path to the latest checkpoint\nlatest_checkpoint = '/kaggle/working/topic_classifier/checkpoint-1500'\n\n# Resume training from the latest checkpoint\ntrainer.train(resume_from_checkpoint=latest_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T12:32:43.859012Z","iopub.execute_input":"2024-12-28T12:32:43.859344Z","iopub.status.idle":"2024-12-28T13:06:21.996727Z","shell.execute_reply.started":"2024-12-28T12:32:43.859316Z","shell.execute_reply":"2024-12-28T13:06:21.995300Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"###### Usuwanie folderu - KLIKNIJ TYLKO JEDEN RAZ!\nimport shutil\nshutil.rmtree(\"/kaggle/working/topic_classifier/checkpoint-3376\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:09:08.482030Z","iopub.execute_input":"2024-12-28T13:09:08.482340Z","iopub.status.idle":"2024-12-28T13:09:08.783501Z","shell.execute_reply.started":"2024-12-28T13:09:08.482319Z","shell.execute_reply":"2024-12-28T13:09:08.782874Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = TrainingArguments(\n\n   output_dir=\"/kaggle/working/topic_classifier\",\n   learning_rate=2e-5,\n   per_device_train_batch_size=3,\n   per_device_eval_batch_size=3,\n   num_train_epochs=5,\n   weight_decay=0.01,\n   evaluation_strategy=\"steps\",\n   eval_steps=100,\n   save_strategy=\"steps\",\n   save_steps=500,\n   load_best_model_at_end=True,\n   save_total_limit=3, \n)\n\ntrainer = Trainer(\n\n   model=model,\n   args=training_args,\n   train_dataset=tokenized_dataset[\"train\"],\n   eval_dataset=tokenized_dataset[\"test\"],\n   tokenizer=tokenizer,\n   data_collator=data_collator,\n   compute_metrics=compute_metrics,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:09:38.478918Z","iopub.execute_input":"2024-12-28T13:09:38.479242Z","iopub.status.idle":"2024-12-28T13:09:38.531909Z","shell.execute_reply.started":"2024-12-28T13:09:38.479218Z","shell.execute_reply":"2024-12-28T13:09:38.531036Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Path to the latest checkpoint\nlatest_checkpoint = '/kaggle/working/topic_classifier/checkpoint-3000'\n\n# Resume training from the latest checkpoint\ntrainer.train(resume_from_checkpoint=latest_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:09:46.499562Z","iopub.execute_input":"2024-12-28T13:09:46.499965Z","iopub.status.idle":"2024-12-28T13:33:08.451686Z","shell.execute_reply.started":"2024-12-28T13:09:46.499933Z","shell.execute_reply":"2024-12-28T13:33:08.450422Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = TrainingArguments(\n\n   output_dir=\"/kaggle/working/topic_classifier\",\n   learning_rate=2e-5,\n   per_device_train_batch_size=3,\n   per_device_eval_batch_size=3,\n   num_train_epochs=6,\n   weight_decay=0.01,\n   evaluation_strategy=\"steps\",\n   eval_steps=100,\n   save_strategy=\"steps\",\n   save_steps=500,\n   load_best_model_at_end=True,\n   save_total_limit=3, \n)\n\ntrainer = Trainer(\n\n   model=model,\n   args=training_args,\n   train_dataset=tokenized_dataset[\"train\"],\n   eval_dataset=tokenized_dataset[\"test\"],\n   tokenizer=tokenizer,\n   data_collator=data_collator,\n   compute_metrics=compute_metrics,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T13:34:11.546792Z","iopub.execute_input":"2024-12-28T13:34:11.547109Z","execution_failed":"2024-12-28T13:34:13.063Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"last_run_id = \"uiul4m7h\"  # fetch the run_id from your wandb workspace\n\n# resume the wandb run from the run_id\nwith wandb.init(\n    project=os.environ[\"WANDB_PROJECT\"],\n    id=last_run_id,\n    resume=\"must\",\n) as run:\n    # Connect an Artifact to the run\n    my_checkpoint_name = f\"checkpoint-{last_run_id}:latest\"\n    my_checkpoint_artifact = run.use_artifact(\"model-uiul4m7h:v10\")\n\n    # Download checkpoint to a folder and return the path\n    checkpoint_dir = my_checkpoint_artifact.download()\n\n    # reinitialize your model and trainer\n    model = AutoModelForSequenceClassification.from_pretrained(\n        \"/kaggle/working/artifacts/model-uiul4m7h:v10\", num_labels=len(classes)\n    )\n    # your awesome training arguments here.\n    training_args = TrainingArguments(\n\n       output_dir=\"/kaggle/working/topic_classifier\",\n       learning_rate=2e-5,\n       per_device_train_batch_size=3,\n       per_device_eval_batch_size=3,\n       num_train_epochs=6,\n       weight_decay=0.01,\n       evaluation_strategy=\"steps\",\n       eval_steps=100,\n       save_strategy=\"steps\",\n       save_steps=500,\n       load_best_model_at_end=True,\n       save_total_limit=3, \n    )\n    \n    trainer = Trainer(\n    \n       model=model,\n       args=training_args,\n       train_dataset=tokenized_dataset[\"train\"],\n       eval_dataset=tokenized_dataset[\"test\"],\n       tokenizer=tokenizer,\n       data_collator=data_collator,\n       compute_metrics=compute_metrics,\n    )\n\n    # make sure use the checkpoint dir to resume training from the checkpoint\n    trainer.train(resume_from_checkpoint=checkpoint_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:00:52.939796Z","iopub.execute_input":"2024-12-28T14:00:52.940104Z","iopub.status.idle":"2024-12-28T14:21:22.792679Z","shell.execute_reply.started":"2024-12-28T14:00:52.940081Z","shell.execute_reply":"2024-12-28T14:21:22.791862Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241228_140052-uiul4m7h</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Resuming run <strong><a href='https://wandb.ai/czarnybaranie1-sgh-warsaw-school-of-economics/tedx_topic_classification/runs/uiul4m7h' target=\"_blank\">/kaggle/working/topic_classifier</a></strong> to <a href='https://wandb.ai/czarnybaranie1-sgh-warsaw-school-of-economics/tedx_topic_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/czarnybaranie1-sgh-warsaw-school-of-economics/tedx_topic_classification' target=\"_blank\">https://wandb.ai/czarnybaranie1-sgh-warsaw-school-of-economics/tedx_topic_classification</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/czarnybaranie1-sgh-warsaw-school-of-economics/tedx_topic_classification/runs/uiul4m7h' target=\"_blank\">https://wandb.ai/czarnybaranie1-sgh-warsaw-school-of-economics/tedx_topic_classification/runs/uiul4m7h</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-uiul4m7h:v10, 4667.12MB. 12 files... \n\u001b[34m\u001b[1mwandb\u001b[0m:   12 of 12 files downloaded.  \nDone. 0:0:6.0\nYou passed along `num_labels=3` with an incompatible id to label map: {'0': 'AI', '1': 'art', '2': 'business', '3': 'climate change', '4': 'communication', '5': 'creativity', '6': 'culture', '7': 'design', '8': 'economics', '9': 'education', '10': 'entertainment', '11': 'environment', '12': 'food', '13': 'gender', '14': 'global issues', '15': 'health', '16': 'history', '17': 'humanity', '18': 'innovation', '19': 'literature', '20': 'mental health', '21': 'music', '22': 'nature', '23': 'personal growth', '24': 'politics', '25': 'psychology', '26': 'science', '27': 'social change', '28': 'storytelling', '29': 'sustainability', '30': 'technology', '31': 'work'}. The number of labels wil be overwritten to 32.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nYou are resuming training from a checkpoint trained with 4.47.1 of Transformers but your current version is 4.44.2. This is not recommended and could yield to errors or unwanted behaviors.\nThere were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3098: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2833: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint_rng_state = torch.load(rng_file)\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5064' max='5064' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5064/5064 20:01, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Roc Auc</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>4100</td>\n      <td>0.022900</td>\n      <td>0.062643</td>\n      <td>0.662420</td>\n      <td>0.804120</td>\n      <td>0.612164</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.022900</td>\n      <td>0.063960</td>\n      <td>0.654777</td>\n      <td>0.800451</td>\n      <td>0.605845</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>0.022900</td>\n      <td>0.063859</td>\n      <td>0.661311</td>\n      <td>0.804808</td>\n      <td>0.616114</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.022900</td>\n      <td>0.063616</td>\n      <td>0.663543</td>\n      <td>0.803802</td>\n      <td>0.612164</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.021700</td>\n      <td>0.064191</td>\n      <td>0.662988</td>\n      <td>0.804515</td>\n      <td>0.613744</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>0.021700</td>\n      <td>0.063434</td>\n      <td>0.670908</td>\n      <td>0.808566</td>\n      <td>0.622433</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>0.021700</td>\n      <td>0.063608</td>\n      <td>0.664977</td>\n      <td>0.806821</td>\n      <td>0.616114</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>0.021700</td>\n      <td>0.064099</td>\n      <td>0.669779</td>\n      <td>0.807777</td>\n      <td>0.621643</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>0.021700</td>\n      <td>0.064007</td>\n      <td>0.666106</td>\n      <td>0.808719</td>\n      <td>0.623223</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.018900</td>\n      <td>0.063890</td>\n      <td>0.670598</td>\n      <td>0.810401</td>\n      <td>0.626382</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/topic_classifier/checkpoint-4500)... Done. 34.0s\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/topic_classifier/checkpoint-5000)... Done. 31.4s\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/topic_classifier/checkpoint-5064)... Done. 38.7s\nCould not locate the best model at /kaggle/working/topic_classifier/checkpoint-2600/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▃▁▅▃▄▇▅▆▇█</td></tr><tr><td>eval/f1</td><td>▄▁▄▅▅█▅█▆█</td></tr><tr><td>eval/loss</td><td>▁▇▇▅█▅▅█▇▇</td></tr><tr><td>eval/roc_auc</td><td>▄▁▄▃▄▇▅▆▇█</td></tr><tr><td>eval/runtime</td><td>█▂▃▄▂▄▁█▆▃</td></tr><tr><td>eval/samples_per_second</td><td>▁▇▆▅▇▅█▁▃▆</td></tr><tr><td>eval/steps_per_second</td><td>▁▇▆▅▇▅█▁▃▆</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇███</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▄▄▅▅▆▇███</td></tr><tr><td>train/grad_norm</td><td>█▁</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.62638</td></tr><tr><td>eval/f1</td><td>0.6706</td></tr><tr><td>eval/loss</td><td>0.06389</td></tr><tr><td>eval/roc_auc</td><td>0.8104</td></tr><tr><td>eval/runtime</td><td>42.8456</td></tr><tr><td>eval/samples_per_second</td><td>29.548</td></tr><tr><td>eval/steps_per_second</td><td>4.925</td></tr><tr><td>total_flos</td><td>933381470013696.0</td></tr><tr><td>train/epoch</td><td>6</td></tr><tr><td>train/global_step</td><td>5064</td></tr><tr><td>train/grad_norm</td><td>0.19754</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0189</td></tr><tr><td>train_loss</td><td>0.00426</td></tr><tr><td>train_runtime</td><td>1176.4185</td></tr><tr><td>train_samples_per_second</td><td>25.828</td></tr><tr><td>train_steps_per_second</td><td>4.305</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">/kaggle/working/topic_classifier</strong> at: <a href='https://wandb.ai/czarnybaranie1-sgh-warsaw-school-of-economics/tedx_topic_classification/runs/uiul4m7h' target=\"_blank\">https://wandb.ai/czarnybaranie1-sgh-warsaw-school-of-economics/tedx_topic_classification/runs/uiul4m7h</a><br> View project at: <a href='https://wandb.ai/czarnybaranie1-sgh-warsaw-school-of-economics/tedx_topic_classification' target=\"_blank\">https://wandb.ai/czarnybaranie1-sgh-warsaw-school-of-economics/tedx_topic_classification</a><br>Synced 5 W&B file(s), 0 media file(s), 24 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241228_140052-uiul4m7h/logs</code>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"from huggingface_hub import PyTorchModelHubMixin\nmodel_name = \"/kaggle/working/topic_classifier/checkpoint-5064\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\nmodel.push_to_hub(\"CzarnyBaranie/tedx-topic-classifier\",private=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T14:26:09.735582Z","iopub.execute_input":"2024-12-28T14:26:09.735907Z","iopub.status.idle":"2024-12-28T14:26:57.784025Z","shell.execute_reply.started":"2024-12-28T14:26:09.735881Z","shell.execute_reply":"2024-12-28T14:26:57.783309Z"}},"outputs":[{"name":"stderr","text":"You passed along `num_labels=3` with an incompatible id to label map: {'0': 'AI', '1': 'art', '2': 'business', '3': 'climate change', '4': 'communication', '5': 'creativity', '6': 'culture', '7': 'design', '8': 'economics', '9': 'education', '10': 'entertainment', '11': 'environment', '12': 'food', '13': 'gender', '14': 'global issues', '15': 'health', '16': 'history', '17': 'humanity', '18': 'innovation', '19': 'literature', '20': 'mental health', '21': 'music', '22': 'nature', '23': 'personal growth', '24': 'politics', '25': 'psychology', '26': 'science', '27': 'social change', '28': 'storytelling', '29': 'sustainability', '30': 'technology', '31': 'work'}. The number of labels wil be overwritten to 32.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9fddfc8a13d41bd884d8926dcbc0b89"}},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/CzarnyBaranie/tedx-topic-classifier/commit/be9c1c3acc6f9bac905aa8e689b026979bbde9c9', commit_message='Upload BartForSequenceClassification', commit_description='', oid='be9c1c3acc6f9bac905aa8e689b026979bbde9c9', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"# inference","metadata":{}},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained('CzarnyBaranie/bart-finetuned-for-tedx-topics')\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"CzarnyBaranie/bart-finetuned-for-tedx-topics\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T10:25:59.971774Z","iopub.execute_input":"2024-12-29T10:25:59.972182Z","iopub.status.idle":"2024-12-29T10:26:41.914656Z","shell.execute_reply.started":"2024-12-29T10:25:59.972144Z","shell.execute_reply":"2024-12-29T10:26:41.913978Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"967d561cdfb047a8ab230e9d01f995e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5b019976d674d9084382006e27113ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a1195f8ebfa44bbb9ccb98b7ceb000c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50ed635547c648f7b895ca4cd5f55a0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e780cab229d647aea063985e9b5f6204"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf4ed20b00e7445f86b65ffc1ee8a3dd"}},"metadata":{}},{"name":"stderr","text":"You passed along `num_labels=3` with an incompatible id to label map: {'0': 'AI', '1': 'art', '2': 'business', '3': 'climate change', '4': 'communication', '5': 'creativity', '6': 'culture', '7': 'design', '8': 'economics', '9': 'education', '10': 'entertainment', '11': 'environment', '12': 'food', '13': 'gender', '14': 'global issues', '15': 'health', '16': 'history', '17': 'humanity', '18': 'innovation', '19': 'literature', '20': 'mental health', '21': 'music', '22': 'nature', '23': 'personal growth', '24': 'politics', '25': 'psychology', '26': 'science', '27': 'social change', '28': 'storytelling', '29': 'sustainability', '30': 'technology', '31': 'work'}. The number of labels wil be overwritten to 32.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"651cf20547d647caa5f1638ecf0ea472"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from transformers import pipeline\nclassifier = pipeline(\"zero-shot-classification\",\n                      model=\"CzarnyBaranie/bart-finetuned-for-tedx-topics\", \n                     device=0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:22:29.888544Z","iopub.execute_input":"2024-12-29T00:22:29.888907Z","iopub.status.idle":"2024-12-29T00:23:11.160179Z","shell.execute_reply.started":"2024-12-29T00:22:29.888878Z","shell.execute_reply":"2024-12-29T00:23:11.159466Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e237769c3fe7432fbc60e4c119783fde"}},"metadata":{}},{"name":"stderr","text":"You passed along `num_labels=3` with an incompatible id to label map: {'0': 'AI', '1': 'art', '2': 'business', '3': 'climate change', '4': 'communication', '5': 'creativity', '6': 'culture', '7': 'design', '8': 'economics', '9': 'education', '10': 'entertainment', '11': 'environment', '12': 'food', '13': 'gender', '14': 'global issues', '15': 'health', '16': 'history', '17': 'humanity', '18': 'innovation', '19': 'literature', '20': 'mental health', '21': 'music', '22': 'nature', '23': 'personal growth', '24': 'politics', '25': 'psychology', '26': 'science', '27': 'social change', '28': 'storytelling', '29': 'sustainability', '30': 'technology', '31': 'work'}. The number of labels wil be overwritten to 32.\nYou passed along `num_labels=3` with an incompatible id to label map: {'0': 'AI', '1': 'art', '2': 'business', '3': 'climate change', '4': 'communication', '5': 'creativity', '6': 'culture', '7': 'design', '8': 'economics', '9': 'education', '10': 'entertainment', '11': 'environment', '12': 'food', '13': 'gender', '14': 'global issues', '15': 'health', '16': 'history', '17': 'humanity', '18': 'innovation', '19': 'literature', '20': 'mental health', '21': 'music', '22': 'nature', '23': 'personal growth', '24': 'politics', '25': 'psychology', '26': 'science', '27': 'social change', '28': 'storytelling', '29': 'sustainability', '30': 'technology', '31': 'work'}. The number of labels wil be overwritten to 32.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"986c663eead64e0c87382a82758ff277"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f021d1bca5fd4bbaa860866d3de0da6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab6f80e132794f4a93af5cd9b33fa798"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9ef511857604335b27dd057ba01969a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40b11c9b676c426ebfda883e8f22685d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"529508fd4dbd46879b109d51be07f52b"}},"metadata":{}},{"name":"stderr","text":"Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"list(model.config.id2label.values())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:23:15.947678Z","iopub.execute_input":"2024-12-29T00:23:15.947981Z","iopub.status.idle":"2024-12-29T00:23:15.953938Z","shell.execute_reply.started":"2024-12-29T00:23:15.947956Z","shell.execute_reply":"2024-12-29T00:23:15.952964Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"['AI',\n 'art',\n 'business',\n 'climate change',\n 'communication',\n 'creativity',\n 'culture',\n 'design',\n 'economics',\n 'education',\n 'entertainment',\n 'environment',\n 'food',\n 'gender',\n 'global issues',\n 'health',\n 'history',\n 'humanity',\n 'innovation',\n 'literature',\n 'mental health',\n 'music',\n 'nature',\n 'personal growth',\n 'politics',\n 'psychology',\n 'science',\n 'social change',\n 'storytelling',\n 'sustainability',\n 'technology',\n 'work']"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"labels=list(model.config.id2label.values())\nlabels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:40:51.213887Z","iopub.execute_input":"2024-12-29T00:40:51.214172Z","iopub.status.idle":"2024-12-29T00:40:51.219409Z","shell.execute_reply.started":"2024-12-29T00:40:51.214149Z","shell.execute_reply":"2024-12-29T00:40:51.218571Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"['AI',\n 'art',\n 'business',\n 'climate change',\n 'communication',\n 'creativity',\n 'culture',\n 'design',\n 'economics',\n 'education',\n 'entertainment',\n 'environment',\n 'food',\n 'gender',\n 'global issues',\n 'health',\n 'history',\n 'humanity',\n 'innovation',\n 'literature',\n 'mental health',\n 'music',\n 'nature',\n 'personal growth',\n 'politics',\n 'psychology',\n 'science',\n 'social change',\n 'storytelling',\n 'sustainability',\n 'technology',\n 'work']"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"print(model.config.id2label)\nprint(model.config.label2id)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:41:17.237018Z","iopub.execute_input":"2024-12-29T00:41:17.237310Z","iopub.status.idle":"2024-12-29T00:41:17.242331Z","shell.execute_reply.started":"2024-12-29T00:41:17.237287Z","shell.execute_reply":"2024-12-29T00:41:17.241464Z"}},"outputs":[{"name":"stdout","text":"{0: 'AI', 1: 'art', 2: 'business', 3: 'climate change', 4: 'communication', 5: 'creativity', 6: 'culture', 7: 'design', 8: 'economics', 9: 'education', 10: 'entertainment', 11: 'environment', 12: 'food', 13: 'gender', 14: 'global issues', 15: 'health', 16: 'history', 17: 'humanity', 18: 'innovation', 19: 'literature', 20: 'mental health', 21: 'music', 22: 'nature', 23: 'personal growth', 24: 'politics', 25: 'psychology', 26: 'science', 27: 'social change', 28: 'storytelling', 29: 'sustainability', 30: 'technology', 31: 'work'}\n{'AI': 0, 'art': 1, 'business': 2, 'climate change': 3, 'communication': 4, 'creativity': 5, 'culture': 6, 'design': 7, 'economics': 8, 'education': 9, 'entertainment': 10, 'environment': 11, 'food': 12, 'gender': 13, 'global issues': 14, 'health': 15, 'history': 16, 'humanity': 17, 'innovation': 18, 'literature': 19, 'mental health': 20, 'music': 21, 'nature': 22, 'personal growth': 23, 'politics': 24, 'psychology': 25, 'science': 26, 'social change': 27, 'storytelling': 28, 'sustainability': 29, 'technology': 30, 'work': 31}\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"labels=list(model.config.id2label.values())\nlabels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:40:38.635337Z","iopub.execute_input":"2024-12-29T00:40:38.635643Z","iopub.status.idle":"2024-12-29T00:40:38.641026Z","shell.execute_reply.started":"2024-12-29T00:40:38.635619Z","shell.execute_reply":"2024-12-29T00:40:38.640335Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"['AI',\n 'art',\n 'business',\n 'climate change',\n 'communication',\n 'creativity',\n 'culture',\n 'design',\n 'economics',\n 'education',\n 'entertainment',\n 'environment',\n 'food',\n 'gender',\n 'global issues',\n 'health',\n 'history',\n 'humanity',\n 'innovation',\n 'literature',\n 'mental health',\n 'music',\n 'nature',\n 'personal growth',\n 'politics',\n 'psychology',\n 'science',\n 'social change',\n 'storytelling',\n 'sustainability',\n 'technology',\n 'work']"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"sequence_to_classify = \"How poetry saved me from a cult\"\nlabels=list(model.config.id2label.values())\nclassification = classifier(sequence_to_classify,labels, multi_label=False)\nclassification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:48:35.566818Z","iopub.execute_input":"2024-12-29T00:48:35.567097Z","iopub.status.idle":"2024-12-29T00:48:36.206688Z","shell.execute_reply.started":"2024-12-29T00:48:35.567075Z","shell.execute_reply":"2024-12-29T00:48:36.205924Z"}},"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"{'sequence': 'How poetry saved me from a cult',\n 'labels': ['work',\n  'mental health',\n  'economics',\n  'food',\n  'business',\n  'gender',\n  'climate change',\n  'AI',\n  'literature',\n  'culture',\n  'nature',\n  'education',\n  'communication',\n  'personal growth',\n  'creativity',\n  'history',\n  'entertainment',\n  'humanity',\n  'art',\n  'environment',\n  'politics',\n  'storytelling',\n  'design',\n  'global issues',\n  'psychology',\n  'innovation',\n  'health',\n  'music',\n  'technology',\n  'science',\n  'social change',\n  'sustainability'],\n 'scores': [0.0683063343167305,\n  0.06420928239822388,\n  0.06332815438508987,\n  0.06300736963748932,\n  0.050007857382297516,\n  0.04787668585777283,\n  0.04645151644945145,\n  0.0328267440199852,\n  0.03210783749818802,\n  0.03205064684152603,\n  0.03203142434358597,\n  0.02991892211139202,\n  0.029693666845560074,\n  0.029527846723794937,\n  0.02822027914226055,\n  0.02795073762536049,\n  0.026581551879644394,\n  0.02576313354074955,\n  0.025392694398760796,\n  0.024150889366865158,\n  0.023202823475003242,\n  0.022452257573604584,\n  0.022302938625216484,\n  0.022274985909461975,\n  0.022056421265006065,\n  0.0215736236423254,\n  0.019301630556583405,\n  0.017276426777243614,\n  0.014904472976922989,\n  0.013003731146454811,\n  0.012219555675983429,\n  0.010027497075498104]}"},"metadata":{}}],"execution_count":74},{"cell_type":"code","source":"print(classification[\"labels\"][0]) # get label with highest score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T23:19:44.014887Z","iopub.execute_input":"2024-12-28T23:19:44.015298Z","iopub.status.idle":"2024-12-28T23:19:44.020015Z","shell.execute_reply.started":"2024-12-28T23:19:44.015264Z","shell.execute_reply":"2024-12-28T23:19:44.019167Z"}},"outputs":[{"name":"stdout","text":"economics\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Dane wejściowe\nsequence_to_classify = \"How poetry saved me from a cult\"\ncandidate_labels = list(model.config.id2label.values())\n\n# Przygotowanie danych: łączenie tekstu z każdą etykietą jako hipotezą\ninputs = tokenizer(\n    [sequence_to_classify] * len(candidate_labels),  # Tekst powtarzany dla każdej etykiety\n    [f\"This text is about {label}.\" for label in candidate_labels],  # Hipotezy\n    return_tensors=\"pt\",  # Zwróć tensory\n    padding=True,  # Wyrównanie do największej długości\n    truncation=True  # Obcięcie do maksymalnej długości modelu\n).to(\"cuda\")\n\n# Predykcja\noutputs = model(**inputs)\nlogits = outputs.logits  # Surowe logity\nprobs = torch.softmax(logits, dim=1)  # Prawdopodobieństwa\n\n# Wyświetlanie wyników\nfor label, prob in zip(candidate_labels, probs[:, 1].tolist()):  # Zakładamy, że \"1\" oznacza zgodność\n    print(f\"Label: {label}, Probability: {prob:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T10:41:52.758300Z","iopub.execute_input":"2024-12-29T10:41:52.758607Z","iopub.status.idle":"2024-12-29T10:41:52.951443Z","shell.execute_reply.started":"2024-12-29T10:41:52.758583Z","shell.execute_reply":"2024-12-29T10:41:52.950697Z"}},"outputs":[{"name":"stdout","text":"Label: AI, Probability: 0.0072\nLabel: art, Probability: 0.9805\nLabel: business, Probability: 0.0010\nLabel: climate change, Probability: 0.0023\nLabel: communication, Probability: 0.0027\nLabel: creativity, Probability: 0.0133\nLabel: culture, Probability: 0.0058\nLabel: design, Probability: 0.0257\nLabel: economics, Probability: 0.0018\nLabel: education, Probability: 0.0002\nLabel: entertainment, Probability: 0.1318\nLabel: environment, Probability: 0.0021\nLabel: food, Probability: 0.0024\nLabel: gender, Probability: 0.0005\nLabel: global issues, Probability: 0.0477\nLabel: health, Probability: 0.0003\nLabel: history, Probability: 0.1197\nLabel: humanity, Probability: 0.2154\nLabel: innovation, Probability: 0.0015\nLabel: literature, Probability: 0.0138\nLabel: mental health, Probability: 0.0008\nLabel: music, Probability: 0.0009\nLabel: nature, Probability: 0.0028\nLabel: personal growth, Probability: 0.0015\nLabel: politics, Probability: 0.1086\nLabel: psychology, Probability: 0.0003\nLabel: science, Probability: 0.0017\nLabel: social change, Probability: 0.0021\nLabel: storytelling, Probability: 0.0634\nLabel: sustainability, Probability: 0.0003\nLabel: technology, Probability: 0.0066\nLabel: work, Probability: 0.0444\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(classifier.model.config.id2label)\nprint(classifier.model.config.label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:48:06.128862Z","iopub.execute_input":"2024-12-29T00:48:06.129184Z","iopub.status.idle":"2024-12-29T00:48:06.134047Z","shell.execute_reply.started":"2024-12-29T00:48:06.129159Z","shell.execute_reply":"2024-12-29T00:48:06.133151Z"}},"outputs":[{"name":"stdout","text":"{0: 'AI', 1: 'art', 2: 'business', 3: 'climate change', 4: 'communication', 5: 'creativity', 6: 'culture', 7: 'design', 8: 'economics', 9: 'education', 10: 'entertainment', 11: 'environment', 12: 'food', 13: 'gender', 14: 'global issues', 15: 'health', 16: 'history', 17: 'humanity', 18: 'innovation', 19: 'literature', 20: 'mental health', 21: 'music', 22: 'nature', 23: 'personal growth', 24: 'politics', 25: 'psychology', 26: 'science', 27: 'social change', 28: 'storytelling', 29: 'sustainability', 30: 'technology', 31: 'work'}\n{'AI': 0, 'art': 1, 'business': 2, 'climate change': 3, 'communication': 4, 'creativity': 5, 'culture': 6, 'design': 7, 'economics': 8, 'education': 9, 'entertainment': 10, 'environment': 11, 'food': 12, 'gender': 13, 'global issues': 14, 'health': 15, 'history': 16, 'humanity': 17, 'innovation': 18, 'literature': 19, 'mental health': 20, 'music': 21, 'nature': 22, 'personal growth': 23, 'politics': 24, 'psychology': 25, 'science': 26, 'social change': 27, 'storytelling': 28, 'sustainability': 29, 'technology': 30, 'work': 31}\n","output_type":"stream"}],"execution_count":73},{"cell_type":"markdown","source":"# On full dataset","metadata":{}},{"cell_type":"markdown","source":"## test dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntest_df = pd.read_csv('/kaggle/input/terdx-finetuning/topics_test.csv')\ntest_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T23:46:43.716239Z","iopub.execute_input":"2024-12-28T23:46:43.716569Z","iopub.status.idle":"2024-12-28T23:46:43.734883Z","shell.execute_reply.started":"2024-12-28T23:46:43.716546Z","shell.execute_reply":"2024-12-28T23:46:43.734179Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"                                                  title        best_tag\n0     What is melatonin -- and should you take it to...          health\n1                                     The world in 2200   social change\n2             The real story behind Archimedes' Eureka!         history\n3                    Are you technically fit to parent?      psychology\n4                               Big data is better data      technology\n...                                                 ...             ...\n1261                      What \"Orwellian\" really means      literature\n1262                       1,000 TED Talks in six words    storytelling\n1263  We actually have a shot at stopping the climat...  climate change\n1264  The billion-dollar campaign to electrify trans...  sustainability\n1265                 A drone's-eye view of conservation  sustainability\n\n[1266 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>best_tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is melatonin -- and should you take it to...</td>\n      <td>health</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The world in 2200</td>\n      <td>social change</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The real story behind Archimedes' Eureka!</td>\n      <td>history</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Are you technically fit to parent?</td>\n      <td>psychology</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Big data is better data</td>\n      <td>technology</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1261</th>\n      <td>What \"Orwellian\" really means</td>\n      <td>literature</td>\n    </tr>\n    <tr>\n      <th>1262</th>\n      <td>1,000 TED Talks in six words</td>\n      <td>storytelling</td>\n    </tr>\n    <tr>\n      <th>1263</th>\n      <td>We actually have a shot at stopping the climat...</td>\n      <td>climate change</td>\n    </tr>\n    <tr>\n      <th>1264</th>\n      <td>The billion-dollar campaign to electrify trans...</td>\n      <td>sustainability</td>\n    </tr>\n    <tr>\n      <th>1265</th>\n      <td>A drone's-eye view of conservation</td>\n      <td>sustainability</td>\n    </tr>\n  </tbody>\n</table>\n<p>1266 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"test_df['predicted_tag'] = None\ntest_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T23:48:44.085935Z","iopub.execute_input":"2024-12-28T23:48:44.086215Z","iopub.status.idle":"2024-12-28T23:48:44.096558Z","shell.execute_reply.started":"2024-12-28T23:48:44.086192Z","shell.execute_reply":"2024-12-28T23:48:44.095705Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"                                                  title        best_tag  \\\n0     What is melatonin -- and should you take it to...          health   \n1                                     The world in 2200   social change   \n2             The real story behind Archimedes' Eureka!         history   \n3                    Are you technically fit to parent?      psychology   \n4                               Big data is better data      technology   \n...                                                 ...             ...   \n1261                      What \"Orwellian\" really means      literature   \n1262                       1,000 TED Talks in six words    storytelling   \n1263  We actually have a shot at stopping the climat...  climate change   \n1264  The billion-dollar campaign to electrify trans...  sustainability   \n1265                 A drone's-eye view of conservation  sustainability   \n\n     predicted_tag  \n0             None  \n1             None  \n2             None  \n3             None  \n4             None  \n...            ...  \n1261          None  \n1262          None  \n1263          None  \n1264          None  \n1265          None  \n\n[1266 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>best_tag</th>\n      <th>predicted_tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is melatonin -- and should you take it to...</td>\n      <td>health</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The world in 2200</td>\n      <td>social change</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The real story behind Archimedes' Eureka!</td>\n      <td>history</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Are you technically fit to parent?</td>\n      <td>psychology</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Big data is better data</td>\n      <td>technology</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1261</th>\n      <td>What \"Orwellian\" really means</td>\n      <td>literature</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1262</th>\n      <td>1,000 TED Talks in six words</td>\n      <td>storytelling</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1263</th>\n      <td>We actually have a shot at stopping the climat...</td>\n      <td>climate change</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1264</th>\n      <td>The billion-dollar campaign to electrify trans...</td>\n      <td>sustainability</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1265</th>\n      <td>A drone's-eye view of conservation</td>\n      <td>sustainability</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>1266 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"from tqdm import tqdm\n\nfor i in tqdm(range(len(test_df))):\n    text = test_df.loc[i,\"title\"]\n    # Perform zero-shot classification on the text\n    candidate_labels = list(model.config.id2label.values())\n    results = classifier(\n        text,\n        candidate_labels=candidate_labels,\n        device=\"cuda\"\n    )\n    # Get the predicted labels and assign a value to the target column\n    label = results[\"labels\"][0]\n    test_df.loc[i, \"predicted_tag\"] = label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:24:04.745221Z","iopub.execute_input":"2024-12-29T00:24:04.745568Z","iopub.status.idle":"2024-12-29T00:36:11.537920Z","shell.execute_reply.started":"2024-12-29T00:24:04.745541Z","shell.execute_reply":"2024-12-29T00:36:11.536926Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1266/1266 [12:06<00:00,  1.74it/s]\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, classification_report\n\n# Zakładamy, że dane są w pandas DataFrame, np. df\ny_true = test_df[\"best_tag\"]  # Poprawne etykiety\ny_pred = test_df[\"predicted_tag\"]  # Przewidywania modelu\n\n# Obliczanie metryk\naccuracy = accuracy_score(y_true, y_pred)\nrecall = recall_score(y_true, y_pred, average=\"weighted\")  # Dostosuj 'average' do przypadku (binary/multiclass)\nf1 = f1_score(y_true, y_pred, average=\"weighted\")\nclassification_rep = classification_report(y_true, y_pred)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1 Score: {f1}\")\nprint(\"Classification Report:\")\nprint(classification_rep)\n\n# Obliczanie ROC-AUC (tylko dla klasyfikacji binarnej lub wieloetykietowej z wartościami prawdopodobieństwa)\n# Załóżmy, że `classifier` zwraca również prawdopodobieństwa w `probs`.\n# probs = classifier(..., return_probas=True)  # Prawdopodobieństwa dla każdej klasy\n# y_prob = [probs[i][positive_class_idx] for i in range(len(probs))]  # Wyodrębnienie prawdopodobieństw dla pozytywnej klasy\n# roc_auc = roc_auc_score(y_true, y_prob, multi_class=\"ovr\")  # Ustaw multi_class w przypadku wieloklasowego problemu\n# print(f\"ROC-AUC: {roc_auc}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:36:54.374530Z","iopub.execute_input":"2024-12-29T00:36:54.374866Z","iopub.status.idle":"2024-12-29T00:36:54.448994Z","shell.execute_reply.started":"2024-12-29T00:36:54.374841Z","shell.execute_reply":"2024-12-29T00:36:54.447877Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.01579778830963665\nRecall: 0.01579778830963665\nF1 Score: 0.002786937185488641\nClassification Report:\n                 precision    recall  f1-score   support\n\n             AI       0.00      0.00      0.00        19\n            art       0.00      0.00      0.00        36\n       business       0.00      0.00      0.00        29\n climate change       0.00      0.00      0.00        21\n  communication       0.00      0.00      0.00        22\n     creativity       0.00      0.00      0.00        25\n        culture       0.00      0.00      0.00        40\n         design       0.00      0.00      0.00        22\n      economics       0.00      0.00      0.00        21\n      education       0.00      0.00      0.00        60\n  entertainment       0.00      0.00      0.00        15\n    environment       0.00      0.00      0.00        15\n           food       0.06      0.12      0.09        16\n         gender       0.02      0.03      0.03        33\n  global issues       0.00      0.00      0.00        43\n         health       0.00      0.00      0.00       106\n        history       0.00      0.00      0.00        65\n       humanity       0.00      0.00      0.00        17\n     innovation       0.00      0.00      0.00        17\n     literature       0.00      0.00      0.00        11\n  mental health       0.01      0.17      0.02        24\n          music       0.00      0.00      0.00        26\n         nature       0.00      0.00      0.00        33\npersonal growth       0.00      0.00      0.00        61\n       politics       0.00      0.00      0.00        43\n     psychology       0.00      0.00      0.00        57\n        science       0.00      0.00      0.00       112\n  social change       0.00      0.00      0.00        83\n   storytelling       0.00      0.00      0.00        19\n sustainability       0.00      0.00      0.00        72\n     technology       0.00      0.00      0.00        88\n           work       0.03      0.87      0.05        15\n\n       accuracy                           0.02      1266\n      macro avg       0.00      0.04      0.01      1266\n   weighted avg       0.00      0.02      0.00      1266\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T00:37:11.556137Z","iopub.execute_input":"2024-12-29T00:37:11.556437Z","iopub.status.idle":"2024-12-29T00:37:11.568201Z","shell.execute_reply.started":"2024-12-29T00:37:11.556414Z","shell.execute_reply":"2024-12-29T00:37:11.567440Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"                                                  title        best_tag  \\\n0     What is melatonin -- and should you take it to...          health   \n1                                     The world in 2200   social change   \n2             The real story behind Archimedes' Eureka!         history   \n3                    Are you technically fit to parent?      psychology   \n4                               Big data is better data      technology   \n...                                                 ...             ...   \n1261                      What \"Orwellian\" really means      literature   \n1262                       1,000 TED Talks in six words    storytelling   \n1263  We actually have a shot at stopping the climat...  climate change   \n1264  The billion-dollar campaign to electrify trans...  sustainability   \n1265                 A drone's-eye view of conservation  sustainability   \n\n      predicted_tag  \n0     mental health  \n1     mental health  \n2            gender  \n3              work  \n4              work  \n...             ...  \n1261           work  \n1262           work  \n1263  mental health  \n1264  mental health  \n1265      economics  \n\n[1266 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>best_tag</th>\n      <th>predicted_tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is melatonin -- and should you take it to...</td>\n      <td>health</td>\n      <td>mental health</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The world in 2200</td>\n      <td>social change</td>\n      <td>mental health</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The real story behind Archimedes' Eureka!</td>\n      <td>history</td>\n      <td>gender</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Are you technically fit to parent?</td>\n      <td>psychology</td>\n      <td>work</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Big data is better data</td>\n      <td>technology</td>\n      <td>work</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1261</th>\n      <td>What \"Orwellian\" really means</td>\n      <td>literature</td>\n      <td>work</td>\n    </tr>\n    <tr>\n      <th>1262</th>\n      <td>1,000 TED Talks in six words</td>\n      <td>storytelling</td>\n      <td>work</td>\n    </tr>\n    <tr>\n      <th>1263</th>\n      <td>We actually have a shot at stopping the climat...</td>\n      <td>climate change</td>\n      <td>mental health</td>\n    </tr>\n    <tr>\n      <th>1264</th>\n      <td>The billion-dollar campaign to electrify trans...</td>\n      <td>sustainability</td>\n      <td>mental health</td>\n    </tr>\n    <tr>\n      <th>1265</th>\n      <td>A drone's-eye view of conservation</td>\n      <td>sustainability</td>\n      <td>economics</td>\n    </tr>\n  </tbody>\n</table>\n<p>1266 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"import pandas as pd\ntedx_df = pd.read_csv('/kaggle/input/tedy-with-lang/tedx_videos_extended_with_lang.csv')\ntedx_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T23:41:30.020992Z","iopub.execute_input":"2024-12-28T23:41:30.021311Z","iopub.status.idle":"2024-12-28T23:41:30.862045Z","shell.execute_reply.started":"2024-12-28T23:41:30.021289Z","shell.execute_reply":"2024-12-28T23:41:30.861345Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"                                               full_title    views  \\\n0       What Shakespeare teaches us about modern consp...  15518.0   \n1       How poetry saved me from a cult | Diannely Ant...  14758.0   \n2       Why language shapes identity (more than race) ...  25684.0   \n3       On designing a presidential library | Craig Dy...  14181.0   \n4       Why chasing happiness is nuts: What to do inst...  10858.0   \n...                                                   ...      ...   \n226747      TEDxWarwick - Professor Vinesh Raja - 2/28/09   2474.0   \n226748     TEDxWarwick - Professor Steve Fuller - 2/28/09   8460.0   \n226749              TEDxWarwick - Francois Grey - 2/28/09   3480.0   \n226750    TEDxWarwick - Professor Andrew Oswald - 2/28/09   6390.0   \n226751  TEDxWarwick - Professor Philip Zimbardo - 2/28/09  30391.0   \n\n                                    date_str                 date  year  \\\n0       23 godziny temu 13 minut i 11 sekund  2024-12-24 01:00:00  2024   \n1                      1 dzień temu 21 minut  2024-12-24 00:00:00  2024   \n2           2 dni temu 13 minut i 52 sekundy  2024-12-23 00:00:00  2024   \n3                        3 dni temu 20 minut  2024-12-22 00:00:00  2024   \n4                        4 dni temu 16 minut  2024-12-21 00:00:00  2024   \n...                                      ...                  ...   ...   \n226747               15 years ago 29 minutes           2009-12-25  2009   \n226748               15 years ago 24 minutes           2009-12-25  2009   \n226749               15 years ago 27 minutes           2009-12-25  2009   \n226750               15 years ago 24 minutes           2009-12-25  2009   \n226751               15 years ago 27 minutes           2009-12-25  2009   \n\n                                                    title           speaker  \\\n0       What Shakespeare teaches us about modern consp...    Dr. Paul Budra   \n1                         How poetry saved me from a cult  Diannely Antigua   \n2           Why language shapes identity (more than race)      Malaka Grant   \n3                     On designing a presidential library      Craig Dykers   \n4       Why chasing happiness is nuts: What to do instead    Lenorë Lambert   \n...                                                   ...               ...   \n226747      TEDxWarwick - Professor Vinesh Raja - 2/28/09               NaN   \n226748     TEDxWarwick - Professor Steve Fuller - 2/28/09               NaN   \n226749              TEDxWarwick - Francois Grey - 2/28/09               NaN   \n226750    TEDxWarwick - Professor Andrew Oswald - 2/28/09               NaN   \n226751  TEDxWarwick - Professor Philip Zimbardo - 2/28/09               NaN   \n\n                  event language  \n0       TEDxSurreySalon       en  \n1        TEDxPortsmouth       en  \n2            TEDxGeorge       en  \n3             TEDxFargo       es  \n4          TEDxBillings       en  \n...                 ...      ...  \n226747              NaN       en  \n226748              NaN       en  \n226749              NaN       en  \n226750              NaN       en  \n226751              NaN       en  \n\n[226752 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_title</th>\n      <th>views</th>\n      <th>date_str</th>\n      <th>date</th>\n      <th>year</th>\n      <th>title</th>\n      <th>speaker</th>\n      <th>event</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What Shakespeare teaches us about modern consp...</td>\n      <td>15518.0</td>\n      <td>23 godziny temu 13 minut i 11 sekund</td>\n      <td>2024-12-24 01:00:00</td>\n      <td>2024</td>\n      <td>What Shakespeare teaches us about modern consp...</td>\n      <td>Dr. Paul Budra</td>\n      <td>TEDxSurreySalon</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How poetry saved me from a cult | Diannely Ant...</td>\n      <td>14758.0</td>\n      <td>1 dzień temu 21 minut</td>\n      <td>2024-12-24 00:00:00</td>\n      <td>2024</td>\n      <td>How poetry saved me from a cult</td>\n      <td>Diannely Antigua</td>\n      <td>TEDxPortsmouth</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why language shapes identity (more than race) ...</td>\n      <td>25684.0</td>\n      <td>2 dni temu 13 minut i 52 sekundy</td>\n      <td>2024-12-23 00:00:00</td>\n      <td>2024</td>\n      <td>Why language shapes identity (more than race)</td>\n      <td>Malaka Grant</td>\n      <td>TEDxGeorge</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>On designing a presidential library | Craig Dy...</td>\n      <td>14181.0</td>\n      <td>3 dni temu 20 minut</td>\n      <td>2024-12-22 00:00:00</td>\n      <td>2024</td>\n      <td>On designing a presidential library</td>\n      <td>Craig Dykers</td>\n      <td>TEDxFargo</td>\n      <td>es</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Why chasing happiness is nuts: What to do inst...</td>\n      <td>10858.0</td>\n      <td>4 dni temu 16 minut</td>\n      <td>2024-12-21 00:00:00</td>\n      <td>2024</td>\n      <td>Why chasing happiness is nuts: What to do instead</td>\n      <td>Lenorë Lambert</td>\n      <td>TEDxBillings</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>226747</th>\n      <td>TEDxWarwick - Professor Vinesh Raja - 2/28/09</td>\n      <td>2474.0</td>\n      <td>15 years ago 29 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Vinesh Raja - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226748</th>\n      <td>TEDxWarwick - Professor Steve Fuller - 2/28/09</td>\n      <td>8460.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Steve Fuller - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226749</th>\n      <td>TEDxWarwick - Francois Grey - 2/28/09</td>\n      <td>3480.0</td>\n      <td>15 years ago 27 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Francois Grey - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226750</th>\n      <td>TEDxWarwick - Professor Andrew Oswald - 2/28/09</td>\n      <td>6390.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Andrew Oswald - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226751</th>\n      <td>TEDxWarwick - Professor Philip Zimbardo - 2/28/09</td>\n      <td>30391.0</td>\n      <td>15 years ago 27 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Philip Zimbardo - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n<p>226752 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"columns_list = list(tedx_df.columns)\ncolumns_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T23:41:34.961861Z","iopub.execute_input":"2024-12-28T23:41:34.962156Z","iopub.status.idle":"2024-12-28T23:41:34.967217Z","shell.execute_reply.started":"2024-12-28T23:41:34.962133Z","shell.execute_reply":"2024-12-28T23:41:34.966490Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"['full_title',\n 'views',\n 'date_str',\n 'date',\n 'year',\n 'title',\n 'speaker',\n 'event',\n 'language']"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"from tqdm import tqdm\n\nfor i in tqdm(range(len(test_df))):\n    text = tedx_df.iloc[i,\"title\"]\n    # Perform zero-shot classification on the text\n    results = classifier(\n        text,\n        candidate_labels=[\"disaster\",  \"normal\"],\n    )\n    # Get the predicted labels and assign a value to the target column\n    labels = results[\"labels\"]\n    prediction = 1 if labels[0] == \"disaster\" else 0\n    test_df.loc[i, \"target\"] = prediction","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\nfile_dict = {\n  \"test\" : \"/kaggle/input/tedy-with-lang/tedx_videos_extended_with_lang.csv\"\n}\n\ndataset = load_dataset(\n  'csv',\n  data_files=file_dict,\n  delimiter=',',\n  column_names=columns_list,\n  skiprows=1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T23:23:13.235407Z","iopub.execute_input":"2024-12-28T23:23:13.235737Z","iopub.status.idle":"2024-12-28T23:23:15.251207Z","shell.execute_reply.started":"2024-12-28T23:23:13.235712Z","shell.execute_reply":"2024-12-28T23:23:15.250589Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf044ef801434b7ba77609beec45b9ed"}},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"def data():\n    for i in range(1000):\n        yield f\"My example {i}\"\n\n\npipe = pipeline(model=\"openai-community/gpt2\", device=0)\ngenerated_characters = 0\nfor out in pipe(data()):\n    generated_characters += len(out[0][\"generated_text\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T23:23:40.099752Z","iopub.execute_input":"2024-12-28T23:23:40.100553Z","iopub.status.idle":"2024-12-28T23:23:40.106299Z","shell.execute_reply.started":"2024-12-28T23:23:40.100517Z","shell.execute_reply":"2024-12-28T23:23:40.105616Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    test: Dataset({\n        features: ['full_title', 'views', 'date_str', 'date', 'year', 'title', 'speaker', 'event', 'language'],\n        num_rows: 226752\n    })\n})"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"%%time\ncandidate_labels = list(model.config.id2label.values())\nzeroshot_preds = classifier(dataset[\"test\"][\"title\"], candidate_labels, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T23:31:24.025067Z","iopub.execute_input":"2024-12-28T23:31:24.025439Z","iopub.status.idle":"2024-12-28T23:34:50.067347Z","shell.execute_reply.started":"2024-12-28T23:31:24.025413Z","shell.execute_reply":"2024-12-28T23:34:50.066530Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/zero_shot_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unable to understand extra arguments {args}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis_template\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"This example is {}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1236\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                 )\n\u001b[0;32m-> 1238\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1239\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1162\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/zero_shot_classification.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"use_cache\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"use_cache\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         model_outputs = {\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1819\u001b[0m         \u001b[0meos_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_consecutive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meos_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All examples must have the same number of <eos> tokens.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m         sentence_representation = hidden_states[eos_mask, :].view(hidden_states.size(0), -1, hidden_states.size(-1))[\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36m_consecutive_return_output\u001b[0;34m(input, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unique_consecutive_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique_consecutive_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36m_unique_consecutive_impl\u001b[0;34m(input, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    974\u001b[0m             \u001b[0munique_consecutive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m             return_counts=return_counts, dim=dim)\n\u001b[0;32m--> 976\u001b[0;31m     output, inverse_indices, counts = _VF.unique_consecutive(  # type: ignore[attr-defined]\n\u001b[0m\u001b[1;32m    977\u001b[0m         input, return_inverse=return_inverse, return_counts=return_counts, dim=dim)\n\u001b[1;32m    978\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":34},{"cell_type":"code","source":"zeroshot_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T23:35:02.689340Z","iopub.execute_input":"2024-12-28T23:35:02.689701Z","iopub.status.idle":"2024-12-28T23:35:02.719941Z","shell.execute_reply.started":"2024-12-28T23:35:02.689675Z","shell.execute_reply":"2024-12-28T23:35:02.718933Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-f2dce8f9bca1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mzeroshot_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'zeroshot_preds' is not defined"],"ename":"NameError","evalue":"name 'zeroshot_preds' is not defined","output_type":"error"}],"execution_count":35},{"cell_type":"code","source":"all_model_outputs = []\nfor preprocessed in classifier.preprocess(dataset[\"test\"][\"title\"][3],candidate_labels):\n    model_outputs = classifier.forward(preprocessed)\n    all_model_outputs.append(model_outputs)\noutputs = classifier.postprocess(all_model_outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T23:45:03.910757Z","iopub.execute_input":"2024-12-28T23:45:03.911065Z","iopub.status.idle":"2024-12-28T23:45:04.813465Z","shell.execute_reply.started":"2024-12-28T23:45:03.911042Z","shell.execute_reply":"2024-12-28T23:45:04.812754Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T23:45:06.555469Z","iopub.execute_input":"2024-12-28T23:45:06.555754Z","iopub.status.idle":"2024-12-28T23:45:06.561151Z","shell.execute_reply.started":"2024-12-28T23:45:06.555733Z","shell.execute_reply":"2024-12-28T23:45:06.560395Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"{'sequence': 'On designing a presidential library',\n 'labels': ['mental health',\n  'food',\n  'economics',\n  'AI',\n  'literature',\n  'work',\n  'business',\n  'communication',\n  'innovation',\n  'education',\n  'gender',\n  'culture',\n  'design',\n  'creativity',\n  'nature',\n  'environment',\n  'humanity',\n  'entertainment',\n  'technology',\n  'history',\n  'science',\n  'politics',\n  'art',\n  'climate change',\n  'health',\n  'storytelling',\n  'personal growth',\n  'global issues',\n  'psychology',\n  'music',\n  'social change',\n  'sustainability'],\n 'scores': [0.06548116356134415,\n  0.06246044859290123,\n  0.06139868497848511,\n  0.05238157883286476,\n  0.039313409477472305,\n  0.036209989339113235,\n  0.035150595009326935,\n  0.034618258476257324,\n  0.03361990302801132,\n  0.0329565592110157,\n  0.032920874655246735,\n  0.032761067152023315,\n  0.03238565847277641,\n  0.032188501209020615,\n  0.03218214586377144,\n  0.03208659589290619,\n  0.02996162138879299,\n  0.02914244867861271,\n  0.027894774451851845,\n  0.026636896654963493,\n  0.02436130866408348,\n  0.024156920611858368,\n  0.023808885365724564,\n  0.02218320220708847,\n  0.02133561298251152,\n  0.021334495395421982,\n  0.021059755235910416,\n  0.02057328075170517,\n  0.020508605986833572,\n  0.018078070133924484,\n  0.011408833786845207,\n  0.00943982508033514]}"},"metadata":{}}],"execution_count":49},{"cell_type":"markdown","source":"# Final inference","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntest_df = pd.read_csv('/kaggle/input/terdx-finetuning/topics_test.csv')\ntest_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T10:30:02.453288Z","iopub.execute_input":"2024-12-29T10:30:02.453806Z","iopub.status.idle":"2024-12-29T10:30:02.736422Z","shell.execute_reply.started":"2024-12-29T10:30:02.453777Z","shell.execute_reply":"2024-12-29T10:30:02.735685Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                  title        best_tag\n0     What is melatonin -- and should you take it to...          health\n1                                     The world in 2200   social change\n2             The real story behind Archimedes' Eureka!         history\n3                    Are you technically fit to parent?      psychology\n4                               Big data is better data      technology\n...                                                 ...             ...\n1261                      What \"Orwellian\" really means      literature\n1262                       1,000 TED Talks in six words    storytelling\n1263  We actually have a shot at stopping the climat...  climate change\n1264  The billion-dollar campaign to electrify trans...  sustainability\n1265                 A drone's-eye view of conservation  sustainability\n\n[1266 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>best_tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is melatonin -- and should you take it to...</td>\n      <td>health</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The world in 2200</td>\n      <td>social change</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The real story behind Archimedes' Eureka!</td>\n      <td>history</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Are you technically fit to parent?</td>\n      <td>psychology</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Big data is better data</td>\n      <td>technology</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1261</th>\n      <td>What \"Orwellian\" really means</td>\n      <td>literature</td>\n    </tr>\n    <tr>\n      <th>1262</th>\n      <td>1,000 TED Talks in six words</td>\n      <td>storytelling</td>\n    </tr>\n    <tr>\n      <th>1263</th>\n      <td>We actually have a shot at stopping the climat...</td>\n      <td>climate change</td>\n    </tr>\n    <tr>\n      <th>1264</th>\n      <td>The billion-dollar campaign to electrify trans...</td>\n      <td>sustainability</td>\n    </tr>\n    <tr>\n      <th>1265</th>\n      <td>A drone's-eye view of conservation</td>\n      <td>sustainability</td>\n    </tr>\n  </tbody>\n</table>\n<p>1266 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nmodel_path = \"CzarnyBaranie/bart-finetuned-for-tedx-topics\"  # Update with your path\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\ntokenizer = AutoTokenizer.from_pretrained(model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T10:53:02.779305Z","iopub.execute_input":"2024-12-29T10:53:02.779643Z","iopub.status.idle":"2024-12-29T10:53:03.915937Z","shell.execute_reply.started":"2024-12-29T10:53:02.779621Z","shell.execute_reply":"2024-12-29T10:53:03.915258Z"}},"outputs":[{"name":"stderr","text":"You passed along `num_labels=3` with an incompatible id to label map: {'0': 'AI', '1': 'art', '2': 'business', '3': 'climate change', '4': 'communication', '5': 'creativity', '6': 'culture', '7': 'design', '8': 'economics', '9': 'education', '10': 'entertainment', '11': 'environment', '12': 'food', '13': 'gender', '14': 'global issues', '15': 'health', '16': 'history', '17': 'humanity', '18': 'innovation', '19': 'literature', '20': 'mental health', '21': 'music', '22': 'nature', '23': 'personal growth', '24': 'politics', '25': 'psychology', '26': 'science', '27': 'social change', '28': 'storytelling', '29': 'sustainability', '30': 'technology', '31': 'work'}. The number of labels wil be overwritten to 32.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"text = \"On designing a presidential library\"\ninputs = tokenizer(text, return_tensors=\"pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T10:56:04.790325Z","iopub.execute_input":"2024-12-29T10:56:04.790606Z","iopub.status.idle":"2024-12-29T10:56:04.794602Z","shell.execute_reply.started":"2024-12-29T10:56:04.790584Z","shell.execute_reply":"2024-12-29T10:56:04.793903Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"model.config.id2label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T10:58:33.730030Z","iopub.execute_input":"2024-12-29T10:58:33.730346Z","iopub.status.idle":"2024-12-29T10:58:33.735953Z","shell.execute_reply.started":"2024-12-29T10:58:33.730324Z","shell.execute_reply":"2024-12-29T10:58:33.735229Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{0: 'AI',\n 1: 'art',\n 2: 'business',\n 3: 'climate change',\n 4: 'communication',\n 5: 'creativity',\n 6: 'culture',\n 7: 'design',\n 8: 'economics',\n 9: 'education',\n 10: 'entertainment',\n 11: 'environment',\n 12: 'food',\n 13: 'gender',\n 14: 'global issues',\n 15: 'health',\n 16: 'history',\n 17: 'humanity',\n 18: 'innovation',\n 19: 'literature',\n 20: 'mental health',\n 21: 'music',\n 22: 'nature',\n 23: 'personal growth',\n 24: 'politics',\n 25: 'psychology',\n 26: 'science',\n 27: 'social change',\n 28: 'storytelling',\n 29: 'sustainability',\n 30: 'technology',\n 31: 'work'}"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"with torch.no_grad():  # Disable gradient calculation for inference\n    outputs = model(**inputs)\n    logits = outputs.logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T10:56:06.625526Z","iopub.execute_input":"2024-12-29T10:56:06.625874Z","iopub.status.idle":"2024-12-29T10:56:06.936487Z","shell.execute_reply.started":"2024-12-29T10:56:06.625846Z","shell.execute_reply":"2024-12-29T10:56:06.935532Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import torch\n\n# Apply sigmoid to get probabilities\nsigmoid = torch.nn.Sigmoid()\nprobs = sigmoid(logits.squeeze().cpu())\n\n# Apply threshold to get predictions (e.g., 0.5)\npredictions = (probs >= 0.5).numpy().astype(int)\n\n# Get predicted labels\npredicted_labels = [model.config.id2label[idx] for idx, label in enumerate(predictions) if label == 1] \nprint(predicted_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T10:58:41.119966Z","iopub.execute_input":"2024-12-29T10:58:41.120297Z","iopub.status.idle":"2024-12-29T10:58:41.126428Z","shell.execute_reply.started":"2024-12-29T10:58:41.120268Z","shell.execute_reply":"2024-12-29T10:58:41.125573Z"}},"outputs":[{"name":"stdout","text":"['design']\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T10:40:46.041989Z","iopub.execute_input":"2024-12-29T10:40:46.042295Z","iopub.status.idle":"2024-12-29T10:40:46.052865Z","shell.execute_reply.started":"2024-12-29T10:40:46.042272Z","shell.execute_reply":"2024-12-29T10:40:46.052089Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                  title        best_tag  \\\n0     What is melatonin -- and should you take it to...          health   \n1                                     The world in 2200   social change   \n2             The real story behind Archimedes' Eureka!         history   \n3                    Are you technically fit to parent?      psychology   \n4                               Big data is better data      technology   \n...                                                 ...             ...   \n1261                      What \"Orwellian\" really means      literature   \n1262                       1,000 TED Talks in six words    storytelling   \n1263  We actually have a shot at stopping the climat...  climate change   \n1264  The billion-dollar campaign to electrify trans...  sustainability   \n1265                 A drone's-eye view of conservation  sustainability   \n\n     predicted_tag  \n0              art  \n1              art  \n2              art  \n3              art  \n4              art  \n...            ...  \n1261           art  \n1262           art  \n1263           art  \n1264           art  \n1265           art  \n\n[1266 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>best_tag</th>\n      <th>predicted_tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is melatonin -- and should you take it to...</td>\n      <td>health</td>\n      <td>art</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The world in 2200</td>\n      <td>social change</td>\n      <td>art</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The real story behind Archimedes' Eureka!</td>\n      <td>history</td>\n      <td>art</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Are you technically fit to parent?</td>\n      <td>psychology</td>\n      <td>art</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Big data is better data</td>\n      <td>technology</td>\n      <td>art</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1261</th>\n      <td>What \"Orwellian\" really means</td>\n      <td>literature</td>\n      <td>art</td>\n    </tr>\n    <tr>\n      <th>1262</th>\n      <td>1,000 TED Talks in six words</td>\n      <td>storytelling</td>\n      <td>art</td>\n    </tr>\n    <tr>\n      <th>1263</th>\n      <td>We actually have a shot at stopping the climat...</td>\n      <td>climate change</td>\n      <td>art</td>\n    </tr>\n    <tr>\n      <th>1264</th>\n      <td>The billion-dollar campaign to electrify trans...</td>\n      <td>sustainability</td>\n      <td>art</td>\n    </tr>\n    <tr>\n      <th>1265</th>\n      <td>A drone's-eye view of conservation</td>\n      <td>sustainability</td>\n      <td>art</td>\n    </tr>\n  </tbody>\n</table>\n<p>1266 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, classification_report\n\n# Zakładamy, że dane są w pandas DataFrame, np. df\ny_true = test_df[\"best_tag\"]  # Poprawne etykiety\ny_pred = test_df[\"predicted_tag\"]  # Przewidywania modelu\n\n# Obliczanie metryk\naccuracy = accuracy_score(y_true, y_pred)\nrecall = recall_score(y_true, y_pred, average=\"weighted\")  # Dostosuj 'average' do przypadku (binary/multiclass)\nf1 = f1_score(y_true, y_pred, average=\"weighted\")\nclassification_rep = classification_report(y_true, y_pred)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1 Score: {f1}\")\nprint(\"Classification Report:\")\nprint(classification_rep)\n\n# Obliczanie ROC-AUC (tylko dla klasyfikacji binarnej lub wieloetykietowej z wartościami prawdopodobieństwa)\n# Załóżmy, że `classifier` zwraca również prawdopodobieństwa w `probs`.\n# probs = classifier(..., return_probas=True)  # Prawdopodobieństwa dla każdej klasy\n# y_prob = [probs[i][positive_class_idx] for i in range(len(probs))]  # Wyodrębnienie prawdopodobieństw dla pozytywnej klasy\n# roc_auc = roc_auc_score(y_true, y_prob, multi_class=\"ovr\")  # Ustaw multi_class w przypadku wieloklasowego problemu\n# print(f\"ROC-AUC: {roc_auc}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T10:40:54.743359Z","iopub.execute_input":"2024-12-29T10:40:54.743669Z","iopub.status.idle":"2024-12-29T10:40:54.809241Z","shell.execute_reply.started":"2024-12-29T10:40:54.743646Z","shell.execute_reply":"2024-12-29T10:40:54.808187Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.02764612954186414\nRecall: 0.02764612954186414\nF1 Score: 0.0015563106544286302\nClassification Report:\n                 precision    recall  f1-score   support\n\n             AI       0.00      0.00      0.00        19\n            art       0.03      0.97      0.05        36\n       business       0.00      0.00      0.00        29\n climate change       0.00      0.00      0.00        21\n  communication       0.00      0.00      0.00        22\n     creativity       0.00      0.00      0.00        25\n        culture       0.00      0.00      0.00        40\n         design       0.00      0.00      0.00        22\n      economics       0.00      0.00      0.00        21\n      education       0.00      0.00      0.00        60\n  entertainment       0.00      0.00      0.00        15\n    environment       0.00      0.00      0.00        15\n           food       0.00      0.00      0.00        16\n         gender       0.00      0.00      0.00        33\n  global issues       0.00      0.00      0.00        43\n         health       0.00      0.00      0.00       106\n        history       0.00      0.00      0.00        65\n       humanity       0.00      0.00      0.00        17\n     innovation       0.00      0.00      0.00        17\n     literature       0.00      0.00      0.00        11\n  mental health       0.00      0.00      0.00        24\n          music       0.00      0.00      0.00        26\n         nature       0.00      0.00      0.00        33\npersonal growth       0.00      0.00      0.00        61\n       politics       0.00      0.00      0.00        43\n     psychology       0.00      0.00      0.00        57\n        science       0.00      0.00      0.00       112\n  social change       0.00      0.00      0.00        83\n   storytelling       0.00      0.00      0.00        19\n sustainability       0.00      0.00      0.00        72\n     technology       0.00      0.00      0.00        88\n           work       0.00      0.00      0.00        15\n\n       accuracy                           0.03      1266\n      macro avg       0.00      0.03      0.00      1266\n   weighted avg       0.00      0.03      0.00      1266\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# final inference2","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\nimport numpy as np\nimport pandas as pd  # Ensure pandas is imported\n\ndef predict_on_dataset_batched(model, tokenizer, test_df, batch_size=16):\n    \"\"\"\n    Predicts labels for a dataset using the specified model, tokenizer,\n    and batch size. Handles KeyError by ensuring predicted indices \n    are within the range of id2class keys.\n\n    Args:\n        model: The trained model.\n        tokenizer: The tokenizer used for the model.\n        test_df: The DataFrame containing the text data.\n        batch_size: The size of the batch for inference.\n\n    Returns:\n        A pandas Series containing the predicted labels.\n    \"\"\"\n\n    # Create id2class from model.config.id2label\n    id2class = {int(k): v for k, v in model.config.id2label.items()}\n\n    num_labels = len(id2class)  # Get the number of labels\n    all_predictions = []\n\n    for i in tqdm(range(0, len(test_df), batch_size)):\n        batch_texts = test_df.iloc[i : i + batch_size][\"title\"].tolist()\n        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True)\n\n        with torch.no_grad():\n            outputs = model(**inputs)\n            logits = outputs.logits\n\n        sigmoid = torch.nn.Sigmoid()\n        probs = sigmoid(logits.cpu())\n        predicted_ids = (probs >= 0.5).numpy().astype(int)  \n\n        for j in range(len(batch_texts)):\n            predicted_labels = [id2class[idx] for idx, label in enumerate(predicted_ids[j]) if label == 1 and idx in id2class]\n\n            # If no labels are predicted above the threshold, \n            # select the label with the highest probability within valid range\n            if not predicted_labels:\n                highest_prob_index = np.argmax(probs[j])\n                # Ensure highest_prob_index is within valid range and convert to int\n                highest_prob_index = int(min(highest_prob_index, num_labels - 1))\n                predicted_labels = [id2class[highest_prob_index]]\n\n            all_predictions.append(predicted_labels[0])  # Take the first label\n\n    return pd.Series(all_predictions, index=test_df.index, name=\"target\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T11:18:37.929200Z","iopub.execute_input":"2024-12-29T11:18:37.929491Z","iopub.status.idle":"2024-12-29T11:18:37.936677Z","shell.execute_reply.started":"2024-12-29T11:18:37.929470Z","shell.execute_reply":"2024-12-29T11:18:37.935828Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"test_df[\"target\"] = predict_on_dataset(model, tokenizer, test_df, model.config.id2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T11:02:12.302182Z","iopub.execute_input":"2024-12-29T11:02:12.302499Z","iopub.status.idle":"2024-12-29T11:07:06.004107Z","shell.execute_reply.started":"2024-12-29T11:02:12.302472Z","shell.execute_reply":"2024-12-29T11:07:06.003270Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1266/1266 [04:53<00:00,  4.31it/s]\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"test_df[\"target\"] = predict_on_dataset_batched(model, tokenizer, test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T11:13:51.432242Z","iopub.execute_input":"2024-12-29T11:13:51.432527Z","iopub.status.idle":"2024-12-29T11:15:09.330347Z","shell.execute_reply.started":"2024-12-29T11:13:51.432498Z","shell.execute_reply":"2024-12-29T11:15:09.329517Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 80/80 [01:17<00:00,  1.03it/s]\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T11:15:09.331624Z","iopub.execute_input":"2024-12-29T11:15:09.332071Z","iopub.status.idle":"2024-12-29T11:15:09.342560Z","shell.execute_reply.started":"2024-12-29T11:15:09.332047Z","shell.execute_reply":"2024-12-29T11:15:09.341672Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"                                                  title        best_tag  \\\n0     What is melatonin -- and should you take it to...          health   \n1                                     The world in 2200   social change   \n2             The real story behind Archimedes' Eureka!         history   \n3                    Are you technically fit to parent?      psychology   \n4                               Big data is better data      technology   \n...                                                 ...             ...   \n1261                      What \"Orwellian\" really means      literature   \n1262                       1,000 TED Talks in six words    storytelling   \n1263  We actually have a shot at stopping the climat...  climate change   \n1264  The billion-dollar campaign to electrify trans...  sustainability   \n1265                 A drone's-eye view of conservation  sustainability   \n\n     predicted_tag          target  \n0              art         science  \n1              art   global issues  \n2              art         history  \n3              art      psychology  \n4              art      technology  \n...            ...             ...  \n1261           art         history  \n1262           art   entertainment  \n1263           art  climate change  \n1264           art  sustainability  \n1265           art     environment  \n\n[1266 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>best_tag</th>\n      <th>predicted_tag</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is melatonin -- and should you take it to...</td>\n      <td>health</td>\n      <td>art</td>\n      <td>science</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The world in 2200</td>\n      <td>social change</td>\n      <td>art</td>\n      <td>global issues</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The real story behind Archimedes' Eureka!</td>\n      <td>history</td>\n      <td>art</td>\n      <td>history</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Are you technically fit to parent?</td>\n      <td>psychology</td>\n      <td>art</td>\n      <td>psychology</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Big data is better data</td>\n      <td>technology</td>\n      <td>art</td>\n      <td>technology</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1261</th>\n      <td>What \"Orwellian\" really means</td>\n      <td>literature</td>\n      <td>art</td>\n      <td>history</td>\n    </tr>\n    <tr>\n      <th>1262</th>\n      <td>1,000 TED Talks in six words</td>\n      <td>storytelling</td>\n      <td>art</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>1263</th>\n      <td>We actually have a shot at stopping the climat...</td>\n      <td>climate change</td>\n      <td>art</td>\n      <td>climate change</td>\n    </tr>\n    <tr>\n      <th>1264</th>\n      <td>The billion-dollar campaign to electrify trans...</td>\n      <td>sustainability</td>\n      <td>art</td>\n      <td>sustainability</td>\n    </tr>\n    <tr>\n      <th>1265</th>\n      <td>A drone's-eye view of conservation</td>\n      <td>sustainability</td>\n      <td>art</td>\n      <td>environment</td>\n    </tr>\n  </tbody>\n</table>\n<p>1266 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"test_df[test_df['target'] is None]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T11:09:15.738452Z","iopub.execute_input":"2024-12-29T11:09:15.738778Z","iopub.status.idle":"2024-12-29T11:09:15.786111Z","shell.execute_reply.started":"2024-12-29T11:09:15.738724Z","shell.execute_reply":"2024-12-29T11:09:15.785046Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: False","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-d6367661e549>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m             ):\n\u001b[1;32m   3797\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: False"],"ename":"KeyError","evalue":"False","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, classification_report\n\n# Zakładamy, że dane są w pandas DataFrame, np. df\ny_true = test_df[\"best_tag\"]  # Poprawne etykiety\ny_pred = test_df[\"target\"]  # Przewidywania modelu\n\n# Obliczanie metryk\naccuracy = accuracy_score(y_true, y_pred)\nrecall = recall_score(y_true, y_pred, average=\"weighted\")  # Dostosuj 'average' do przypadku (binary/multiclass)\nf1 = f1_score(y_true, y_pred, average=\"weighted\")\nclassification_rep = classification_report(y_true, y_pred)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1 Score: {f1}\")\nprint(\"Classification Report:\")\nprint(classification_rep)\n\n# Obliczanie ROC-AUC (tylko dla klasyfikacji binarnej lub wieloetykietowej z wartościami prawdopodobieństwa)\n# Załóżmy, że `classifier` zwraca również prawdopodobieństwa w `probs`.\n# probs = classifier(..., return_probas=True)  # Prawdopodobieństwa dla każdej klasy\n# y_prob = [probs[i][positive_class_idx] for i in range(len(probs))]  # Wyodrębnienie prawdopodobieństw dla pozytywnej klasy\n# roc_auc = roc_auc_score(y_true, y_prob, multi_class=\"ovr\")  # Ustaw multi_class w przypadku wieloklasowego problemu\n# print(f\"ROC-AUC: {roc_auc}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T11:15:09.343805Z","iopub.execute_input":"2024-12-29T11:15:09.344010Z","iopub.status.idle":"2024-12-29T11:15:09.406389Z","shell.execute_reply.started":"2024-12-29T11:15:09.343992Z","shell.execute_reply":"2024-12-29T11:15:09.405754Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.6666666666666666\nRecall: 0.6666666666666666\nF1 Score: 0.6658223995330474\nClassification Report:\n                 precision    recall  f1-score   support\n\n             AI       0.79      0.79      0.79        19\n            art       0.60      0.58      0.59        36\n       business       0.72      0.62      0.67        29\n climate change       0.86      0.86      0.86        21\n  communication       0.50      0.41      0.45        22\n     creativity       0.63      0.48      0.55        25\n        culture       0.47      0.50      0.48        40\n         design       0.71      0.68      0.70        22\n      economics       0.76      0.76      0.76        21\n      education       0.72      0.70      0.71        60\n  entertainment       0.33      0.47      0.39        15\n    environment       0.42      0.67      0.51        15\n           food       0.77      0.62      0.69        16\n         gender       0.72      0.70      0.71        33\n  global issues       0.45      0.51      0.48        43\n         health       0.74      0.83      0.78       106\n        history       0.80      0.78      0.79        65\n       humanity       0.71      0.29      0.42        17\n     innovation       0.50      0.47      0.48        17\n     literature       0.86      0.55      0.67        11\n  mental health       0.70      0.67      0.68        24\n          music       0.75      0.92      0.83        26\n         nature       0.60      0.64      0.62        33\npersonal growth       0.65      0.52      0.58        61\n       politics       0.75      0.77      0.76        43\n     psychology       0.55      0.68      0.61        57\n        science       0.65      0.73      0.69       112\n  social change       0.62      0.55      0.59        83\n   storytelling       0.39      0.37      0.38        19\n sustainability       0.75      0.67      0.71        72\n     technology       0.84      0.77      0.80        88\n           work       0.71      0.80      0.75        15\n\n       accuracy                           0.67      1266\n      macro avg       0.66      0.64      0.64      1266\n   weighted avg       0.67      0.67      0.67      1266\n\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tedx_df = pd.read_csv('/kaggle/input/tedy-with-lang/tedx_videos_extended_with_lang.csv')\ntedx_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T11:16:58.554420Z","iopub.execute_input":"2024-12-29T11:16:58.554852Z","iopub.status.idle":"2024-12-29T11:16:59.794635Z","shell.execute_reply.started":"2024-12-29T11:16:58.554816Z","shell.execute_reply":"2024-12-29T11:16:59.793802Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                                               full_title    views  \\\n0       What Shakespeare teaches us about modern consp...  15518.0   \n1       How poetry saved me from a cult | Diannely Ant...  14758.0   \n2       Why language shapes identity (more than race) ...  25684.0   \n3       On designing a presidential library | Craig Dy...  14181.0   \n4       Why chasing happiness is nuts: What to do inst...  10858.0   \n...                                                   ...      ...   \n226747      TEDxWarwick - Professor Vinesh Raja - 2/28/09   2474.0   \n226748     TEDxWarwick - Professor Steve Fuller - 2/28/09   8460.0   \n226749              TEDxWarwick - Francois Grey - 2/28/09   3480.0   \n226750    TEDxWarwick - Professor Andrew Oswald - 2/28/09   6390.0   \n226751  TEDxWarwick - Professor Philip Zimbardo - 2/28/09  30391.0   \n\n                                    date_str                 date  year  \\\n0       23 godziny temu 13 minut i 11 sekund  2024-12-24 01:00:00  2024   \n1                      1 dzień temu 21 minut  2024-12-24 00:00:00  2024   \n2           2 dni temu 13 minut i 52 sekundy  2024-12-23 00:00:00  2024   \n3                        3 dni temu 20 minut  2024-12-22 00:00:00  2024   \n4                        4 dni temu 16 minut  2024-12-21 00:00:00  2024   \n...                                      ...                  ...   ...   \n226747               15 years ago 29 minutes           2009-12-25  2009   \n226748               15 years ago 24 minutes           2009-12-25  2009   \n226749               15 years ago 27 minutes           2009-12-25  2009   \n226750               15 years ago 24 minutes           2009-12-25  2009   \n226751               15 years ago 27 minutes           2009-12-25  2009   \n\n                                                    title           speaker  \\\n0       What Shakespeare teaches us about modern consp...    Dr. Paul Budra   \n1                         How poetry saved me from a cult  Diannely Antigua   \n2           Why language shapes identity (more than race)      Malaka Grant   \n3                     On designing a presidential library      Craig Dykers   \n4       Why chasing happiness is nuts: What to do instead    Lenorë Lambert   \n...                                                   ...               ...   \n226747      TEDxWarwick - Professor Vinesh Raja - 2/28/09               NaN   \n226748     TEDxWarwick - Professor Steve Fuller - 2/28/09               NaN   \n226749              TEDxWarwick - Francois Grey - 2/28/09               NaN   \n226750    TEDxWarwick - Professor Andrew Oswald - 2/28/09               NaN   \n226751  TEDxWarwick - Professor Philip Zimbardo - 2/28/09               NaN   \n\n                  event language  \n0       TEDxSurreySalon       en  \n1        TEDxPortsmouth       en  \n2            TEDxGeorge       en  \n3             TEDxFargo       es  \n4          TEDxBillings       en  \n...                 ...      ...  \n226747              NaN       en  \n226748              NaN       en  \n226749              NaN       en  \n226750              NaN       en  \n226751              NaN       en  \n\n[226752 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_title</th>\n      <th>views</th>\n      <th>date_str</th>\n      <th>date</th>\n      <th>year</th>\n      <th>title</th>\n      <th>speaker</th>\n      <th>event</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What Shakespeare teaches us about modern consp...</td>\n      <td>15518.0</td>\n      <td>23 godziny temu 13 minut i 11 sekund</td>\n      <td>2024-12-24 01:00:00</td>\n      <td>2024</td>\n      <td>What Shakespeare teaches us about modern consp...</td>\n      <td>Dr. Paul Budra</td>\n      <td>TEDxSurreySalon</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How poetry saved me from a cult | Diannely Ant...</td>\n      <td>14758.0</td>\n      <td>1 dzień temu 21 minut</td>\n      <td>2024-12-24 00:00:00</td>\n      <td>2024</td>\n      <td>How poetry saved me from a cult</td>\n      <td>Diannely Antigua</td>\n      <td>TEDxPortsmouth</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why language shapes identity (more than race) ...</td>\n      <td>25684.0</td>\n      <td>2 dni temu 13 minut i 52 sekundy</td>\n      <td>2024-12-23 00:00:00</td>\n      <td>2024</td>\n      <td>Why language shapes identity (more than race)</td>\n      <td>Malaka Grant</td>\n      <td>TEDxGeorge</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>On designing a presidential library | Craig Dy...</td>\n      <td>14181.0</td>\n      <td>3 dni temu 20 minut</td>\n      <td>2024-12-22 00:00:00</td>\n      <td>2024</td>\n      <td>On designing a presidential library</td>\n      <td>Craig Dykers</td>\n      <td>TEDxFargo</td>\n      <td>es</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Why chasing happiness is nuts: What to do inst...</td>\n      <td>10858.0</td>\n      <td>4 dni temu 16 minut</td>\n      <td>2024-12-21 00:00:00</td>\n      <td>2024</td>\n      <td>Why chasing happiness is nuts: What to do instead</td>\n      <td>Lenorë Lambert</td>\n      <td>TEDxBillings</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>226747</th>\n      <td>TEDxWarwick - Professor Vinesh Raja - 2/28/09</td>\n      <td>2474.0</td>\n      <td>15 years ago 29 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Vinesh Raja - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226748</th>\n      <td>TEDxWarwick - Professor Steve Fuller - 2/28/09</td>\n      <td>8460.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Steve Fuller - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226749</th>\n      <td>TEDxWarwick - Francois Grey - 2/28/09</td>\n      <td>3480.0</td>\n      <td>15 years ago 27 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Francois Grey - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226750</th>\n      <td>TEDxWarwick - Professor Andrew Oswald - 2/28/09</td>\n      <td>6390.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Andrew Oswald - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>226751</th>\n      <td>TEDxWarwick - Professor Philip Zimbardo - 2/28/09</td>\n      <td>30391.0</td>\n      <td>15 years ago 27 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Philip Zimbardo - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n<p>226752 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"test_df[\"target\"] = predict_on_dataset_batched(model, tokenizer, tedx_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T11:18:47.826574Z","iopub.execute_input":"2024-12-29T11:18:47.826878Z","iopub.status.idle":"2024-12-29T11:19:07.367935Z","shell.execute_reply.started":"2024-12-29T11:18:47.826854Z","shell.execute_reply":"2024-12-29T11:19:07.366710Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 10/14172 [00:19<7:40:24,  1.95s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-038551d79564>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_on_dataset_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtedx_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-46-bee259c819b9>\u001b[0m in \u001b[0;36mpredict_on_dataset_batched\u001b[0;34m(model, tokenizer, test_df, batch_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1799\u001b[0m             )\n\u001b[1;32m   1800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1801\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1802\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 )\n\u001b[1;32m   1378\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1380\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":48},{"cell_type":"code","source":"# To GPU\nfrom tqdm import tqdm\nimport torch\nimport numpy as np\nimport pandas as pd  # Ensure pandas is imported\n\ndef predict_on_dataset_batched(model, tokenizer, test_df, batch_size=16, device=\"cuda\"):\n    \"\"\"\n    Predicts labels for a dataset using the specified model, tokenizer,\n    and batch size. Handles KeyError by ensuring predicted indices \n    are within the range of id2class keys.\n\n    Args:\n        model: The trained model.\n        tokenizer: The tokenizer used for the model.\n        test_df: The DataFrame containing the text data.\n        batch_size: The size of the batch for inference.\n        device: The device to run the model on ('cuda' for GPU or 'cpu' for CPU).\n\n    Returns:\n        A pandas Series containing the predicted labels.\n    \"\"\"\n\n    # Move model to the specified device\n    model.to(device)\n    model.eval()  # Ensure the model is in evaluation mode\n\n    # Create id2class from model.config.id2label\n    id2class = {int(k): v for k, v in model.config.id2label.items()}\n\n    num_labels = len(id2class)  # Get the number of labels\n    all_predictions = []\n\n    for i in tqdm(range(0, len(test_df), batch_size)):\n        batch_texts = test_df.iloc[i : i + batch_size][\"title\"].tolist()\n        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n\n        with torch.no_grad():\n            outputs = model(**inputs)\n            logits = outputs.logits\n\n        sigmoid = torch.nn.Sigmoid()\n        probs = sigmoid(logits).cpu()  # Move probabilities back to CPU for processing\n        predicted_ids = (probs >= 0.5).numpy().astype(int)  \n\n        for j in range(len(batch_texts)):\n            predicted_labels = [id2class[idx] for idx, label in enumerate(predicted_ids[j]) if label == 1 and idx in id2class]\n\n            # If no labels are predicted above the threshold, \n            # select the label with the highest probability within valid range\n            if not predicted_labels:\n                highest_prob_index = np.argmax(probs[j])\n                # Ensure highest_prob_index is within valid range and convert to int\n                highest_prob_index = int(min(highest_prob_index, num_labels - 1))\n                predicted_labels = [id2class[highest_prob_index]]\n\n            all_predictions.append(predicted_labels[0])  # Take the first label\n\n    return pd.Series(all_predictions, index=test_df.index, name=\"target\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T11:19:43.534613Z","iopub.execute_input":"2024-12-29T11:19:43.534973Z","iopub.status.idle":"2024-12-29T11:19:43.543005Z","shell.execute_reply.started":"2024-12-29T11:19:43.534943Z","shell.execute_reply":"2024-12-29T11:19:43.542053Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"test_df[\"target\"] = predict_on_dataset_batched(model, tokenizer, test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T11:19:59.137364Z","iopub.execute_input":"2024-12-29T11:19:59.137702Z","iopub.status.idle":"2024-12-29T11:20:07.060439Z","shell.execute_reply.started":"2024-12-29T11:19:59.137674Z","shell.execute_reply":"2024-12-29T11:20:07.059570Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 80/80 [00:07<00:00, 10.71it/s]\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, classification_report\n\n# Zakładamy, że dane są w pandas DataFrame, np. df\ny_true = test_df[\"best_tag\"]  # Poprawne etykiety\ny_pred = test_df[\"target\"]  # Przewidywania modelu\n\n# Obliczanie metryk\naccuracy = accuracy_score(y_true, y_pred)\nrecall = recall_score(y_true, y_pred, average=\"weighted\")  # Dostosuj 'average' do przypadku (binary/multiclass)\nf1 = f1_score(y_true, y_pred, average=\"weighted\")\nclassification_rep = classification_report(y_true, y_pred)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1 Score: {f1}\")\nprint(\"Classification Report:\")\nprint(classification_rep)\n\n# Obliczanie ROC-AUC (tylko dla klasyfikacji binarnej lub wieloetykietowej z wartościami prawdopodobieństwa)\n# Załóżmy, że `classifier` zwraca również prawdopodobieństwa w `probs`.\n# probs = classifier(..., return_probas=True)  # Prawdopodobieństwa dla każdej klasy\n# y_prob = [probs[i][positive_class_idx] for i in range(len(probs))]  # Wyodrębnienie prawdopodobieństw dla pozytywnej klasy\n# roc_auc = roc_auc_score(y_true, y_prob, multi_class=\"ovr\")  # Ustaw multi_class w przypadku wieloklasowego problemu\n# print(f\"ROC-AUC: {roc_auc}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T11:20:15.919196Z","iopub.execute_input":"2024-12-29T11:20:15.919477Z","iopub.status.idle":"2024-12-29T11:20:15.986468Z","shell.execute_reply.started":"2024-12-29T11:20:15.919455Z","shell.execute_reply":"2024-12-29T11:20:15.985615Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.6666666666666666\nRecall: 0.6666666666666666\nF1 Score: 0.6658223995330474\nClassification Report:\n                 precision    recall  f1-score   support\n\n             AI       0.79      0.79      0.79        19\n            art       0.60      0.58      0.59        36\n       business       0.72      0.62      0.67        29\n climate change       0.86      0.86      0.86        21\n  communication       0.50      0.41      0.45        22\n     creativity       0.63      0.48      0.55        25\n        culture       0.47      0.50      0.48        40\n         design       0.71      0.68      0.70        22\n      economics       0.76      0.76      0.76        21\n      education       0.72      0.70      0.71        60\n  entertainment       0.33      0.47      0.39        15\n    environment       0.42      0.67      0.51        15\n           food       0.77      0.62      0.69        16\n         gender       0.72      0.70      0.71        33\n  global issues       0.45      0.51      0.48        43\n         health       0.74      0.83      0.78       106\n        history       0.80      0.78      0.79        65\n       humanity       0.71      0.29      0.42        17\n     innovation       0.50      0.47      0.48        17\n     literature       0.86      0.55      0.67        11\n  mental health       0.70      0.67      0.68        24\n          music       0.75      0.92      0.83        26\n         nature       0.60      0.64      0.62        33\npersonal growth       0.65      0.52      0.58        61\n       politics       0.75      0.77      0.76        43\n     psychology       0.55      0.68      0.61        57\n        science       0.65      0.73      0.69       112\n  social change       0.62      0.55      0.59        83\n   storytelling       0.39      0.37      0.38        19\n sustainability       0.75      0.67      0.71        72\n     technology       0.84      0.77      0.80        88\n           work       0.71      0.80      0.75        15\n\n       accuracy                           0.67      1266\n      macro avg       0.66      0.64      0.64      1266\n   weighted avg       0.67      0.67      0.67      1266\n\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"tedx_df[\"target\"] = predict_on_dataset_batched(model, tokenizer, tedx_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T11:20:40.247212Z","iopub.execute_input":"2024-12-29T11:20:40.247601Z","iopub.status.idle":"2024-12-29T11:20:55.081773Z","shell.execute_reply.started":"2024-12-29T11:20:40.247568Z","shell.execute_reply":"2024-12-29T11:20:55.080598Z"}},"outputs":[{"name":"stderr","text":"  1%|          | 98/14172 [00:14<35:25,  6.62it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-e95f1da00ce0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtedx_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_on_dataset_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtedx_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-49-1da80829e842>\u001b[0m in \u001b[0;36mpredict_on_dataset_batched\u001b[0;34m(model, tokenizer, test_df, batch_size, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mbatch_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3053\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3055\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3056\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3057\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_valid_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3115\u001b[0m                 \u001b[0;34m\"text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3116\u001b[0m                 \u001b[0;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."],"ename":"ValueError","evalue":"text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).","output_type":"error"}],"execution_count":52},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# FINAL INFERENCE ! (REALLY)","metadata":{}},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained('CzarnyBaranie/bart-finetuned-for-tedx-topics')\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"CzarnyBaranie/bart-finetuned-for-tedx-topics\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T13:48:34.633221Z","iopub.execute_input":"2024-12-30T13:48:34.633522Z","iopub.status.idle":"2024-12-30T13:49:16.989294Z","shell.execute_reply.started":"2024-12-30T13:48:34.633500Z","shell.execute_reply":"2024-12-30T13:49:16.988058Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ede41bbb5047dfb414077e2eba2df0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53e0dc42d1c44dc09ad5afc00e5e3976"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11147cef61004b56b88b69ed96aa5e8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e54279163c4a4b7bb014fc531c3402a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae0aa66333474aa1ac5fe4f4bc0ee447"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"319d5df6e2dd433683f2b57a5dae7e18"}},"metadata":{}},{"name":"stderr","text":"You passed along `num_labels=3` with an incompatible id to label map: {'0': 'AI', '1': 'art', '2': 'business', '3': 'climate change', '4': 'communication', '5': 'creativity', '6': 'culture', '7': 'design', '8': 'economics', '9': 'education', '10': 'entertainment', '11': 'environment', '12': 'food', '13': 'gender', '14': 'global issues', '15': 'health', '16': 'history', '17': 'humanity', '18': 'innovation', '19': 'literature', '20': 'mental health', '21': 'music', '22': 'nature', '23': 'personal growth', '24': 'politics', '25': 'psychology', '26': 'science', '27': 'social change', '28': 'storytelling', '29': 'sustainability', '30': 'technology', '31': 'work'}. The number of labels wil be overwritten to 32.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c53b0b3515ce49fda28b8ce19d728eb0"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\nimport numpy as np\nimport pandas as pd  # Ensure pandas is imported\n\ndef predict_on_dataset_batched(model, tokenizer, test_df, batch_size=16, device=\"cuda\"):\n    \"\"\"\n    Predicts labels for a dataset using the specified model, tokenizer,\n    and batch size. Handles KeyError by ensuring predicted indices \n    are within the range of id2class keys and ensures text inputs are valid.\n\n    Args:\n        model: The trained model.\n        tokenizer: The tokenizer used for the model.\n        test_df: The DataFrame containing the text data.\n        batch_size: The size of the batch for inference.\n        device: The device to run the model on ('cuda' for GPU or 'cpu' for CPU).\n\n    Returns:\n        A pandas Series containing the predicted labels or None for invalid rows.\n    \"\"\"\n\n    # Move model to the specified device\n    model.to(device)\n    model.eval()  # Ensure the model is in evaluation mode\n\n    # Create id2class from model.config.id2label\n    id2class = {int(k): v for k, v in model.config.id2label.items()}\n\n    num_labels = len(id2class)  # Get the number of labels\n    all_predictions = []\n\n    for i in tqdm(range(0, len(test_df), batch_size)):\n        # Extract batch titles\n        batch_texts = test_df.iloc[i : i + batch_size][\"translated_title\"].tolist()\n\n        # Replace non-string entries with None\n        valid_texts = [text if isinstance(text, str) else None for text in batch_texts]\n\n        # Prepare inputs for valid texts only\n        valid_indices = [j for j, text in enumerate(valid_texts) if text is not None]\n        if valid_indices:\n            inputs = tokenizer([valid_texts[j] for j in valid_indices], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n\n            with torch.no_grad():\n                outputs = model(**inputs)\n                logits = outputs.logits\n\n            sigmoid = torch.nn.Sigmoid()\n            probs = sigmoid(logits).cpu()  # Move probabilities back to CPU for processing\n            predicted_ids = (probs >= 0.5).numpy().astype(int)\n\n            # Process predictions\n            for k, idx in enumerate(valid_indices):\n                predicted_labels = [id2class[idx] for idx, label in enumerate(predicted_ids[k]) if label == 1 and idx in id2class]\n\n                # If no labels are predicted above the threshold, \n                # select the label with the highest probability within valid range\n                if not predicted_labels:\n                    highest_prob_index = np.argmax(probs[k])\n                    # Ensure highest_prob_index is within valid range and convert to int\n                    highest_prob_index = int(min(highest_prob_index, num_labels - 1))\n                    predicted_labels = [id2class[highest_prob_index]]\n\n                all_predictions.append(predicted_labels[0])  # Take the first label\n\n        # For invalid entries, append None\n        for j in range(len(batch_texts)):\n            if j not in valid_indices:\n                all_predictions.append(None)\n\n    return pd.Series(all_predictions, index=test_df.index, name=\"tag\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T13:49:23.813035Z","iopub.execute_input":"2024-12-30T13:49:23.813339Z","iopub.status.idle":"2024-12-30T13:49:23.821699Z","shell.execute_reply.started":"2024-12-30T13:49:23.813313Z","shell.execute_reply":"2024-12-30T13:49:23.820745Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\ntedx_df = pd.read_csv('/kaggle/input/tedx-with-lang-translated/tedx_videos_extended_with_lang_translated.csv')\ntedx_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T13:49:26.500070Z","iopub.execute_input":"2024-12-30T13:49:26.500368Z","iopub.status.idle":"2024-12-30T13:49:27.595816Z","shell.execute_reply.started":"2024-12-30T13:49:26.500336Z","shell.execute_reply":"2024-12-30T13:49:27.594783Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"        Unnamed: 0                                         full_title  \\\n0                0  What Shakespeare teaches us about modern consp...   \n1                1  How poetry saved me from a cult | Diannely Ant...   \n2                2  Why language shapes identity (more than race) ...   \n3                3  On designing a presidential library | Craig Dy...   \n4                4  Why chasing happiness is nuts: What to do inst...   \n...            ...                                                ...   \n226747      226747      TEDxWarwick - Professor Vinesh Raja - 2/28/09   \n226748      226748     TEDxWarwick - Professor Steve Fuller - 2/28/09   \n226749      226749              TEDxWarwick - Francois Grey - 2/28/09   \n226750      226750    TEDxWarwick - Professor Andrew Oswald - 2/28/09   \n226751      226751  TEDxWarwick - Professor Philip Zimbardo - 2/28/09   \n\n          views                              date_str                 date  \\\n0       15518.0  23 godziny temu 13 minut i 11 sekund  2024-12-24 01:00:00   \n1       14758.0                 1 dzień temu 21 minut  2024-12-24 00:00:00   \n2       25684.0      2 dni temu 13 minut i 52 sekundy  2024-12-23 00:00:00   \n3       14181.0                   3 dni temu 20 minut  2024-12-22 00:00:00   \n4       10858.0                   4 dni temu 16 minut  2024-12-21 00:00:00   \n...         ...                                   ...                  ...   \n226747   2474.0               15 years ago 29 minutes           2009-12-25   \n226748   8460.0               15 years ago 24 minutes           2009-12-25   \n226749   3480.0               15 years ago 27 minutes           2009-12-25   \n226750   6390.0               15 years ago 24 minutes           2009-12-25   \n226751  30391.0               15 years ago 27 minutes           2009-12-25   \n\n        year                                              title  \\\n0       2024  What Shakespeare teaches us about modern consp...   \n1       2024                    How poetry saved me from a cult   \n2       2024      Why language shapes identity (more than race)   \n3       2024                On designing a presidential library   \n4       2024  Why chasing happiness is nuts: What to do instead   \n...      ...                                                ...   \n226747  2009      TEDxWarwick - Professor Vinesh Raja - 2/28/09   \n226748  2009     TEDxWarwick - Professor Steve Fuller - 2/28/09   \n226749  2009              TEDxWarwick - Francois Grey - 2/28/09   \n226750  2009    TEDxWarwick - Professor Andrew Oswald - 2/28/09   \n226751  2009  TEDxWarwick - Professor Philip Zimbardo - 2/28/09   \n\n                 speaker            event final_language  \\\n0         Dr. Paul Budra  TEDxSurreySalon             en   \n1       Diannely Antigua   TEDxPortsmouth             en   \n2           Malaka Grant       TEDxGeorge             en   \n3           Craig Dykers        TEDxFargo             en   \n4         Lenorë Lambert     TEDxBillings             en   \n...                  ...              ...            ...   \n226747               NaN              NaN             en   \n226748               NaN              NaN             en   \n226749               NaN              NaN             en   \n226750               NaN              NaN             en   \n226751               NaN              NaN             en   \n\n                                         translated_title  \n0       What Shakespeare teaches us about modern consp...  \n1                         How poetry saved me from a cult  \n2           Why language shapes identity (more than race)  \n3                     On designing a presidential library  \n4       Why chasing happiness is nuts: What to do instead  \n...                                                   ...  \n226747      TEDxWarwick - Professor Vinesh Raja - 2/28/09  \n226748     TEDxWarwick - Professor Steve Fuller - 2/28/09  \n226749              TEDxWarwick - Francois Grey - 2/28/09  \n226750    TEDxWarwick - Professor Andrew Oswald - 2/28/09  \n226751  TEDxWarwick - Professor Philip Zimbardo - 2/28/09  \n\n[226752 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>full_title</th>\n      <th>views</th>\n      <th>date_str</th>\n      <th>date</th>\n      <th>year</th>\n      <th>title</th>\n      <th>speaker</th>\n      <th>event</th>\n      <th>final_language</th>\n      <th>translated_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>What Shakespeare teaches us about modern consp...</td>\n      <td>15518.0</td>\n      <td>23 godziny temu 13 minut i 11 sekund</td>\n      <td>2024-12-24 01:00:00</td>\n      <td>2024</td>\n      <td>What Shakespeare teaches us about modern consp...</td>\n      <td>Dr. Paul Budra</td>\n      <td>TEDxSurreySalon</td>\n      <td>en</td>\n      <td>What Shakespeare teaches us about modern consp...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>How poetry saved me from a cult | Diannely Ant...</td>\n      <td>14758.0</td>\n      <td>1 dzień temu 21 minut</td>\n      <td>2024-12-24 00:00:00</td>\n      <td>2024</td>\n      <td>How poetry saved me from a cult</td>\n      <td>Diannely Antigua</td>\n      <td>TEDxPortsmouth</td>\n      <td>en</td>\n      <td>How poetry saved me from a cult</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Why language shapes identity (more than race) ...</td>\n      <td>25684.0</td>\n      <td>2 dni temu 13 minut i 52 sekundy</td>\n      <td>2024-12-23 00:00:00</td>\n      <td>2024</td>\n      <td>Why language shapes identity (more than race)</td>\n      <td>Malaka Grant</td>\n      <td>TEDxGeorge</td>\n      <td>en</td>\n      <td>Why language shapes identity (more than race)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>On designing a presidential library | Craig Dy...</td>\n      <td>14181.0</td>\n      <td>3 dni temu 20 minut</td>\n      <td>2024-12-22 00:00:00</td>\n      <td>2024</td>\n      <td>On designing a presidential library</td>\n      <td>Craig Dykers</td>\n      <td>TEDxFargo</td>\n      <td>en</td>\n      <td>On designing a presidential library</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Why chasing happiness is nuts: What to do inst...</td>\n      <td>10858.0</td>\n      <td>4 dni temu 16 minut</td>\n      <td>2024-12-21 00:00:00</td>\n      <td>2024</td>\n      <td>Why chasing happiness is nuts: What to do instead</td>\n      <td>Lenorë Lambert</td>\n      <td>TEDxBillings</td>\n      <td>en</td>\n      <td>Why chasing happiness is nuts: What to do instead</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>226747</th>\n      <td>226747</td>\n      <td>TEDxWarwick - Professor Vinesh Raja - 2/28/09</td>\n      <td>2474.0</td>\n      <td>15 years ago 29 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Vinesh Raja - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n      <td>TEDxWarwick - Professor Vinesh Raja - 2/28/09</td>\n    </tr>\n    <tr>\n      <th>226748</th>\n      <td>226748</td>\n      <td>TEDxWarwick - Professor Steve Fuller - 2/28/09</td>\n      <td>8460.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Steve Fuller - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n      <td>TEDxWarwick - Professor Steve Fuller - 2/28/09</td>\n    </tr>\n    <tr>\n      <th>226749</th>\n      <td>226749</td>\n      <td>TEDxWarwick - Francois Grey - 2/28/09</td>\n      <td>3480.0</td>\n      <td>15 years ago 27 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Francois Grey - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n      <td>TEDxWarwick - Francois Grey - 2/28/09</td>\n    </tr>\n    <tr>\n      <th>226750</th>\n      <td>226750</td>\n      <td>TEDxWarwick - Professor Andrew Oswald - 2/28/09</td>\n      <td>6390.0</td>\n      <td>15 years ago 24 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Andrew Oswald - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n      <td>TEDxWarwick - Professor Andrew Oswald - 2/28/09</td>\n    </tr>\n    <tr>\n      <th>226751</th>\n      <td>226751</td>\n      <td>TEDxWarwick - Professor Philip Zimbardo - 2/28/09</td>\n      <td>30391.0</td>\n      <td>15 years ago 27 minutes</td>\n      <td>2009-12-25</td>\n      <td>2009</td>\n      <td>TEDxWarwick - Professor Philip Zimbardo - 2/28/09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>en</td>\n      <td>TEDxWarwick - Professor Philip Zimbardo - 2/28/09</td>\n    </tr>\n  </tbody>\n</table>\n<p>226752 rows × 11 columns</p>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"tedx_df[\"tag\"] = predict_on_dataset_batched(model, tokenizer, tedx_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T13:49:31.980074Z","iopub.execute_input":"2024-12-30T13:49:31.980390Z","iopub.status.idle":"2024-12-30T14:26:17.511004Z","shell.execute_reply.started":"2024-12-30T13:49:31.980366Z","shell.execute_reply":"2024-12-30T14:26:17.510287Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 14172/14172 [36:44<00:00,  6.43it/s] \n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"tedx_df.to_csv(\"/kaggle/working/tedx_df_tag_output.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T14:26:42.969105Z","iopub.execute_input":"2024-12-30T14:26:42.969430Z","iopub.status.idle":"2024-12-30T14:26:44.569746Z","shell.execute_reply.started":"2024-12-30T14:26:42.969404Z","shell.execute_reply":"2024-12-30T14:26:44.568762Z"}},"outputs":[],"execution_count":16}]}